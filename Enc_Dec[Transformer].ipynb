{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enc-Dec[Transformer].ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eM0ZRpl-2TSo",
        "g3MT2gJW7EGf",
        "BQa1ZUCjOJkJ",
        "SR9hPyFAZhU9",
        "arKFuiiZvfq7"
      ],
      "mount_file_id": "1kS9-i3gpQJ5plrCFBtDUr7MTyu_es52K",
      "authorship_tag": "ABX9TyMckerz4+XtQtSy2nsd6Zm4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokoshin0720/ml-tutorials/blob/main/Enc_Dec%5BTransformer%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM0ZRpl-2TSo"
      },
      "source": [
        "# インストール -> 再起動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwAiDqgwzdof",
        "outputId": "4ed50064-fad7-405e-e5c3-263fdab647aa"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "\n",
        "!pip install torchtext==0.8.0\n",
        "!pip install torch==1.7.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "0 upgraded, 21 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 3,877 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Fetched 3,877 kB in 2s (2,216 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "0 packages upgraded, 11 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.3 MB in 3s (9,943 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 161231 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "                            \n",
            "Collecting mecab-python3==0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
            "  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python3: filename=mecab_python3-0.7-cp37-cp37m-linux_x86_64.whl size=156585 sha256=2890bfeeab690e9d00565e4b2b1a6294402a584e82f6109faa706ebdc0244237\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
            "Successfully built mecab-python3\n",
            "Installing collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.7\n",
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed torchtext-0.8.0\n",
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3MT2gJW7EGf"
      },
      "source": [
        "# 必要なモジュールのimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttvyQXX65TbP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext import data\n",
        "from torchtext.data import Field\n",
        "import MeCab"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEvKfdq7LCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756af9c7-6ad3-4d67-be5c-325bc61d83f4"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQa1ZUCjOJkJ"
      },
      "source": [
        "# データの前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90NdlUDA1wfW"
      },
      "source": [
        "分かち書き"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyHkj65R1vZH"
      },
      "source": [
        "def tokenizer(text):\n",
        "    return m.parse(text).split()"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_S-nRnq_G4",
        "outputId": "86fbce2b-c6b9-407d-ee0c-70a7d4305c1f"
      },
      "source": [
        "m = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "# Fieldオブジェクトの作成\n",
        "title = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "right = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "left = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "# CSVファイルを読み込み、TabularDatasetオブジェクトを作成\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = \"/content/drive/MyDrive/data/nakazawa_lab/youtuber_title/\",\n",
        "    train = \"youtube_test.csv\",\n",
        "    test = \"youtube_test.csv\",\n",
        "    format=\"csv\",\n",
        "    fields=[('title', title), ('right', right), ('left', left)]\n",
        ")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_SCdj7e7dJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcb5645-e685-44d2-919c-caccec4d8e0c"
      },
      "source": [
        "for example in train_data[:3]:\n",
        "    print(example.title)\n",
        "    print(example.right)\n",
        "    print(example.left)\n",
        "    print(\"=\"*30)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeff', '結果', 'を', '出す', '前', 'に', '豪語', 'する', '人', 'は', '、', 'たいてい', '小物', '【', '質疑', '応答', '#', '36', '】']\n",
            "['、', 'たいてい', '小物', '【', '質疑', '応答', '#', '36', '】']\n",
            "['、', 'は', '人', 'する', '豪語', 'に', '前', '出す', 'を', '結果']\n",
            "==============================\n",
            "['人生', '変わる', '7', 'つ', 'の', '時間', '感覚', '改善', 'ツール']\n",
            "['時間', '感覚', '改善', 'ツール']\n",
            "['時間', 'の', 'つ', '7', '変わる', '人生']\n",
            "==============================\n",
            "['大衆', 'は', '常に', '間違っ', 'て', 'いる', '。', '特に', 'あなた', 'が', '成功', 'し', 'たい', 'と', '思っ', 'て', 'いる', '場合', 'は', '【', '質疑', '応答', '#', '35', '】']\n",
            "['て', 'いる', '。', '特に', 'あなた', 'が', '成功', 'し', 'たい', 'と', '思っ', 'て', 'いる', '場合', 'は', '【', '質疑', '応答', '#', '35', '】']\n",
            "['て', '間違っ', '常に', 'は', '大衆']\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gmvIbFU9rTT"
      },
      "source": [
        "単語辞書の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAXPGTcj9sds"
      },
      "source": [
        "title.build_vocab(train_data)\n",
        "right.build_vocab(train_data)\n",
        "left.build_vocab(train_data)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7KCicPgOSUm"
      },
      "source": [
        "# Transformerモデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk62jCiuCjCd"
      },
      "source": [
        "Encoder -> memoryを返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr89_Yy_Ca0d"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=forward_expansion,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        encoder_norm = nn.LayerNorm(normalized_shape=embedding_size)\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer=encoder_layer,\n",
        "            num_layers=num_encoder_layers,\n",
        "            norm=encoder_norm\n",
        "        )\n",
        "\n",
        "        self.device = device\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_seq_length, N = src.shape\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        memory = self.encoder(\n",
        "            src=embed_src,\n",
        "            src_key_padding_mask=src_padding_mask\n",
        "        )\n",
        "        return memory\n",
        "\n",
        "        def make_src_mask(self, src):\n",
        "            src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "            return src_mask.to(self.device)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "        return src_mask.to(self.device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7y03Y2iD7GG"
      },
      "source": [
        "Decoder -> memoryを受け取って、生成結果を返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6NweVFND6_F"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        trg_vocab_size,\n",
        "        num_heads,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=embedding_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=forward_expansion,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        decoder_norm = nn.LayerNorm(normalized_shape=embedding_size)\n",
        "\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            decoder_layer=decoder_layer,\n",
        "            num_layers=num_decoder_layers,\n",
        "            norm=decoder_norm\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, memory):\n",
        "        trg_seq_length, N = trg.shape\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "        trg_mask = self.generate_square_subsequent_mask(trg_seq_length).to(self.device)\n",
        "\n",
        "        out = self.decoder(\n",
        "            tgt=embed_trg,\n",
        "            memory=memory,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        return out\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR9hPyFAZhU9"
      },
      "source": [
        "# ハイパーパラメータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLU_27kzZjoB"
      },
      "source": [
        "num_epochs = 100\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAd7zkX0Zkvx"
      },
      "source": [
        "src_vocab_size = len(title.vocab)\n",
        "trg_vocab_size = len(title.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 50\n",
        "forward_expansion = 4\n",
        "src_pad_idx = 0"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvbf5NzJZ3ys"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpNqN2nXZ6Jq",
        "outputId": "d5d3b45f-972c-4805-ecb6-10f8c3043ad1"
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "        (train_data, test_data),\n",
        "        batch_size=batch_size,\n",
        "        sort_within_batch=True,\n",
        "        sort_key=lambda x: len(x.title),\n",
        "        device=device,\n",
        "        )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKeggt1TFC1B"
      },
      "source": [
        "モデルの宣言"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3lleaAJFEcd"
      },
      "source": [
        "encoder = Encoder(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder_left = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder_right = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynez4FnaFeNo"
      },
      "source": [
        "optimizerとloss関数の宣言"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCe3OqdbSUt"
      },
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_left_optimizer = optim.Adam(decoder_left.parameters(), lr=learning_rate)\n",
        "decoder_right_optimizer = optim.Adam(decoder_right.parameters(), lr=learning_rate)\n",
        "\n",
        "encoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    encoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_left_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_left_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_right_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_right_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "\n",
        "pad_idx = 0\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5v4nep9Z1JD",
        "outputId": "c3e90533-b42a-41c3-dff0-c9925a6a36d4"
      },
      "source": [
        "'''\n",
        "Decoderのみ\n",
        "'''\n",
        "encoder = Encoder(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "encoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    encoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "pad_idx = 0\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "'''\n",
        "学習\n",
        "'''\n",
        "mean_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    losses = []\n",
        "    output2bests = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        print(\"=\"*30)\n",
        "        '''\n",
        "        入力データ\n",
        "        '''\n",
        "        inp_data = batch.title.to(device)\n",
        "        target = batch.title.to(device)\n",
        "\n",
        "        '''\n",
        "        encoderとdecoderに渡す\n",
        "        '''\n",
        "        memory = encoder(inp_data)\n",
        "        output = decoder(target[:-1, :], memory)\n",
        "\n",
        "        '''\n",
        "        勾配の初期化\n",
        "        '''\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        '''\n",
        "        loss計算\n",
        "        '''\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        '''\n",
        "        誤差逆伝搬\n",
        "        '''\n",
        "        loss.backward(retain_graph=True)\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "\n",
        "        '''\n",
        "        重みの更新\n",
        "        '''\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        '''\n",
        "        正解率検証\n",
        "        '''\n",
        "        # for b in batch:\n",
        "        #     if b == None: continue\n",
        "        #     for title in b:\n",
        "        #         for i in range(12):\n",
        "        #             print(title[:, i]) # これで文章の列になっている\n",
        "        #             sentence = title[:, i]\n",
        "        # print(output2bests)\n",
        "        # print(batch.title)\n",
        "\n",
        "    '''\n",
        "    バッチの平均ロスを計算\n",
        "    '''\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "\n",
        "    '''\n",
        "    スケジューラー（学習率の調整）\n",
        "    '''\n",
        "    decoder_scheduler.step(mean_loss)\n",
        "    '''\n",
        "    loss append\n",
        "    '''\n",
        "    mean_losses.append(mean_loss)\n",
        "    print(\"loss: \", mean_loss)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 100]\n",
            "==============================\n",
            "loss:  4.925047397613525\n",
            "[Epoch 1 / 100]\n",
            "==============================\n",
            "loss:  3.2984509468078613\n",
            "[Epoch 2 / 100]\n",
            "==============================\n",
            "loss:  3.4900310039520264\n",
            "[Epoch 3 / 100]\n",
            "==============================\n",
            "loss:  3.0082504749298096\n",
            "[Epoch 4 / 100]\n",
            "==============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss:  2.915499210357666\n",
            "[Epoch 5 / 100]\n",
            "==============================\n",
            "loss:  2.736375331878662\n",
            "[Epoch 6 / 100]\n",
            "==============================\n",
            "loss:  2.660460948944092\n",
            "[Epoch 7 / 100]\n",
            "==============================\n",
            "loss:  2.537870168685913\n",
            "[Epoch 8 / 100]\n",
            "==============================\n",
            "loss:  2.4466733932495117\n",
            "[Epoch 9 / 100]\n",
            "==============================\n",
            "loss:  2.362398147583008\n",
            "[Epoch 10 / 100]\n",
            "==============================\n",
            "loss:  2.263850688934326\n",
            "[Epoch 11 / 100]\n",
            "==============================\n",
            "loss:  2.1747195720672607\n",
            "[Epoch 12 / 100]\n",
            "==============================\n",
            "loss:  2.0564146041870117\n",
            "[Epoch 13 / 100]\n",
            "==============================\n",
            "loss:  1.9726804494857788\n",
            "[Epoch 14 / 100]\n",
            "==============================\n",
            "loss:  1.8753373622894287\n",
            "[Epoch 15 / 100]\n",
            "==============================\n",
            "loss:  1.7538468837738037\n",
            "[Epoch 16 / 100]\n",
            "==============================\n",
            "loss:  1.6453932523727417\n",
            "[Epoch 17 / 100]\n",
            "==============================\n",
            "loss:  1.5397677421569824\n",
            "[Epoch 18 / 100]\n",
            "==============================\n",
            "loss:  1.4562197923660278\n",
            "[Epoch 19 / 100]\n",
            "==============================\n",
            "loss:  1.3567721843719482\n",
            "[Epoch 20 / 100]\n",
            "==============================\n",
            "loss:  1.2523783445358276\n",
            "[Epoch 21 / 100]\n",
            "==============================\n",
            "loss:  1.1573165655136108\n",
            "[Epoch 22 / 100]\n",
            "==============================\n",
            "loss:  1.0554534196853638\n",
            "[Epoch 23 / 100]\n",
            "==============================\n",
            "loss:  0.9554420113563538\n",
            "[Epoch 24 / 100]\n",
            "==============================\n",
            "loss:  0.8706664443016052\n",
            "[Epoch 25 / 100]\n",
            "==============================\n",
            "loss:  0.791046679019928\n",
            "[Epoch 26 / 100]\n",
            "==============================\n",
            "loss:  0.7096683382987976\n",
            "[Epoch 27 / 100]\n",
            "==============================\n",
            "loss:  0.627116858959198\n",
            "[Epoch 28 / 100]\n",
            "==============================\n",
            "loss:  0.5638052225112915\n",
            "[Epoch 29 / 100]\n",
            "==============================\n",
            "loss:  0.4902893602848053\n",
            "[Epoch 30 / 100]\n",
            "==============================\n",
            "loss:  0.4303899109363556\n",
            "[Epoch 31 / 100]\n",
            "==============================\n",
            "loss:  0.37446680665016174\n",
            "[Epoch 32 / 100]\n",
            "==============================\n",
            "loss:  0.32885751128196716\n",
            "[Epoch 33 / 100]\n",
            "==============================\n",
            "loss:  0.28982311487197876\n",
            "[Epoch 34 / 100]\n",
            "==============================\n",
            "loss:  0.25939810276031494\n",
            "[Epoch 35 / 100]\n",
            "==============================\n",
            "loss:  0.2284715622663498\n",
            "[Epoch 36 / 100]\n",
            "==============================\n",
            "loss:  0.19536669552326202\n",
            "[Epoch 37 / 100]\n",
            "==============================\n",
            "loss:  0.1716567426919937\n",
            "[Epoch 38 / 100]\n",
            "==============================\n",
            "loss:  0.15042494237422943\n",
            "[Epoch 39 / 100]\n",
            "==============================\n",
            "loss:  0.1331288367509842\n",
            "[Epoch 40 / 100]\n",
            "==============================\n",
            "loss:  0.1156163439154625\n",
            "[Epoch 41 / 100]\n",
            "==============================\n",
            "loss:  0.10537392646074295\n",
            "[Epoch 42 / 100]\n",
            "==============================\n",
            "loss:  0.0927676185965538\n",
            "[Epoch 43 / 100]\n",
            "==============================\n",
            "loss:  0.0830167829990387\n",
            "[Epoch 44 / 100]\n",
            "==============================\n",
            "loss:  0.07371039688587189\n",
            "[Epoch 45 / 100]\n",
            "==============================\n",
            "loss:  0.06781542301177979\n",
            "[Epoch 46 / 100]\n",
            "==============================\n",
            "loss:  0.06024220958352089\n",
            "[Epoch 47 / 100]\n",
            "==============================\n",
            "loss:  0.05634066462516785\n",
            "[Epoch 48 / 100]\n",
            "==============================\n",
            "loss:  0.0507221557199955\n",
            "[Epoch 49 / 100]\n",
            "==============================\n",
            "loss:  0.04528961703181267\n",
            "[Epoch 50 / 100]\n",
            "==============================\n",
            "loss:  0.04197109118103981\n",
            "[Epoch 51 / 100]\n",
            "==============================\n",
            "loss:  0.03903855010867119\n",
            "[Epoch 52 / 100]\n",
            "==============================\n",
            "loss:  0.03560200333595276\n",
            "[Epoch 53 / 100]\n",
            "==============================\n",
            "loss:  0.034457966685295105\n",
            "[Epoch 54 / 100]\n",
            "==============================\n",
            "loss:  0.030666211619973183\n",
            "[Epoch 55 / 100]\n",
            "==============================\n",
            "loss:  0.028355812653899193\n",
            "[Epoch 56 / 100]\n",
            "==============================\n",
            "loss:  0.02611321397125721\n",
            "[Epoch 57 / 100]\n",
            "==============================\n",
            "loss:  0.024802744388580322\n",
            "[Epoch 58 / 100]\n",
            "==============================\n",
            "loss:  0.023993579670786858\n",
            "[Epoch 59 / 100]\n",
            "==============================\n",
            "loss:  0.022913256660103798\n",
            "[Epoch 60 / 100]\n",
            "==============================\n",
            "loss:  0.019548572599887848\n",
            "[Epoch 61 / 100]\n",
            "==============================\n",
            "loss:  0.02019508183002472\n",
            "[Epoch 62 / 100]\n",
            "==============================\n",
            "loss:  0.019915413111448288\n",
            "[Epoch 63 / 100]\n",
            "==============================\n",
            "loss:  0.017726268619298935\n",
            "[Epoch 64 / 100]\n",
            "==============================\n",
            "loss:  0.016896473243832588\n",
            "[Epoch 65 / 100]\n",
            "==============================\n",
            "loss:  0.016067389398813248\n",
            "[Epoch 66 / 100]\n",
            "==============================\n",
            "loss:  0.015417026355862617\n",
            "[Epoch 67 / 100]\n",
            "==============================\n",
            "loss:  0.015113521367311478\n",
            "[Epoch 68 / 100]\n",
            "==============================\n",
            "loss:  0.01415986381471157\n",
            "[Epoch 69 / 100]\n",
            "==============================\n",
            "loss:  0.014668300747871399\n",
            "[Epoch 70 / 100]\n",
            "==============================\n",
            "loss:  0.014102861285209656\n",
            "[Epoch 71 / 100]\n",
            "==============================\n",
            "loss:  0.013217730447649956\n",
            "[Epoch 72 / 100]\n",
            "==============================\n",
            "loss:  0.012591236270964146\n",
            "[Epoch 73 / 100]\n",
            "==============================\n",
            "loss:  0.013246256858110428\n",
            "[Epoch 74 / 100]\n",
            "==============================\n",
            "loss:  0.011997469700872898\n",
            "[Epoch 75 / 100]\n",
            "==============================\n",
            "loss:  0.011882156133651733\n",
            "[Epoch 76 / 100]\n",
            "==============================\n",
            "loss:  0.011410016566514969\n",
            "[Epoch 77 / 100]\n",
            "==============================\n",
            "loss:  0.010729287751019001\n",
            "[Epoch 78 / 100]\n",
            "==============================\n",
            "loss:  0.010729412548244\n",
            "[Epoch 79 / 100]\n",
            "==============================\n",
            "loss:  0.010100490413606167\n",
            "[Epoch 80 / 100]\n",
            "==============================\n",
            "loss:  0.010233069770038128\n",
            "[Epoch 81 / 100]\n",
            "==============================\n",
            "loss:  0.009847386740148067\n",
            "[Epoch 82 / 100]\n",
            "==============================\n",
            "loss:  0.00978055503219366\n",
            "[Epoch 83 / 100]\n",
            "==============================\n",
            "loss:  0.009595135226845741\n",
            "[Epoch 84 / 100]\n",
            "==============================\n",
            "loss:  0.00915033183991909\n",
            "[Epoch 85 / 100]\n",
            "==============================\n",
            "loss:  0.009097490459680557\n",
            "[Epoch 86 / 100]\n",
            "==============================\n",
            "loss:  0.009274630807340145\n",
            "[Epoch 87 / 100]\n",
            "==============================\n",
            "loss:  0.008704178035259247\n",
            "[Epoch 88 / 100]\n",
            "==============================\n",
            "loss:  0.008666232228279114\n",
            "[Epoch 89 / 100]\n",
            "==============================\n",
            "loss:  0.008620290085673332\n",
            "[Epoch 90 / 100]\n",
            "==============================\n",
            "loss:  0.00803627260029316\n",
            "[Epoch 91 / 100]\n",
            "==============================\n",
            "loss:  0.008159627206623554\n",
            "[Epoch 92 / 100]\n",
            "==============================\n",
            "loss:  0.008032364770770073\n",
            "[Epoch 93 / 100]\n",
            "==============================\n",
            "loss:  0.007920556701719761\n",
            "[Epoch 94 / 100]\n",
            "==============================\n",
            "loss:  0.007690278813242912\n",
            "[Epoch 95 / 100]\n",
            "==============================\n",
            "loss:  0.00742023391649127\n",
            "[Epoch 96 / 100]\n",
            "==============================\n",
            "loss:  0.007609606720507145\n",
            "[Epoch 97 / 100]\n",
            "==============================\n",
            "loss:  0.007466509472578764\n",
            "[Epoch 98 / 100]\n",
            "==============================\n",
            "loss:  0.007126184646040201\n",
            "[Epoch 99 / 100]\n",
            "==============================\n",
            "loss:  0.0069427452981472015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGCDg6IfGGC-"
      },
      "source": [
        "学習開始(Encoder-Decoderモデル)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGX4ZjWPGI00"
      },
      "source": [
        "# mean_losses_left = []\n",
        "# mean_losses_right = []\n",
        "# losses = []\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "#     losses_left = []\n",
        "#     losses_right = []\n",
        "\n",
        "#     for batch_idx, batch in enumerate(train_iterator):\n",
        "#         '''\n",
        "#         入力データ\n",
        "#         '''\n",
        "#         inp_data = batch.title.to(device)\n",
        "#         target_left = batch.left.to(device)\n",
        "#         target_right = batch.right.to(device)\n",
        "\n",
        "#         '''\n",
        "#         encoderとdecoderに渡す\n",
        "#         '''\n",
        "#         memory = encoder(inp_data)\n",
        "#         output_left = decoder_left(target_left[:-1, :], memory)\n",
        "#         output_right = decoder_right(target_right[:-1, :], memory)\n",
        "\n",
        "#         '''\n",
        "#         outputの形式を変更\n",
        "#         '''\n",
        "#         output_left = output_left.reshape(-1, output_left.shape[2])\n",
        "#         target_left = target_left[1:].reshape(-1)\n",
        "#         output_right = output_right.reshape(-1, output_right.shape[2])\n",
        "#         target_right = target_right[1:].reshape(-1)\n",
        "\n",
        "#         '''\n",
        "#         勾配の初期化\n",
        "#         '''\n",
        "#         encoder_optimizer.zero_grad()\n",
        "#         decoder_left_optimizer.zero_grad()\n",
        "#         decoder_right_optimizer.zero_grad()\n",
        "\n",
        "#         '''\n",
        "#         loss計算\n",
        "#         '''\n",
        "#         loss_left = criterion(output_left, target_left)\n",
        "#         loss_right = criterion(output_right, target_right)\n",
        "#         losses_left.append(loss_left.item())\n",
        "#         losses_right.append(loss_right.item())\n",
        "\n",
        "#         '''\n",
        "#         誤差逆伝搬\n",
        "#         '''\n",
        "#         loss_left.backward(retain_graph=True)\n",
        "#         loss_right.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "#         torch.nn.utils.clip_grad_norm_(decoder_left.parameters(), max_norm=1)\n",
        "#         torch.nn.utils.clip_grad_norm_(decoder_right.parameters(), max_norm=1)\n",
        "\n",
        "#         '''\n",
        "#         重みの更新\n",
        "#         '''\n",
        "#         encoder_optimizer.step()\n",
        "#         decoder_left_optimizer.step()\n",
        "#         decoder_right_optimizer.step()\n",
        "\n",
        "#     '''\n",
        "#     バッチの平均ロスを計算\n",
        "#     '''\n",
        "#     mean_loss_left = sum(losses_left) / len(losses_left)\n",
        "#     mean_loss_right = sum(losses_right) / len(losses_right)\n",
        "\n",
        "#     '''\n",
        "#     スケジューラー（学習率の調整）\n",
        "#     '''\n",
        "#     decoder_left_scheduler.step(mean_loss_left)\n",
        "#     decoder_right_scheduler.step(mean_loss_right)\n",
        "#     '''\n",
        "#     loss append\n",
        "#     '''\n",
        "#     mean_losses_left.append(mean_loss_left)\n",
        "#     mean_losses_right.append(mean_loss_right)\n",
        "#     print(\"left: \", mean_loss_left)\n",
        "#     print(\"right: \", mean_loss_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiftllNUu8sg"
      },
      "source": [
        "損失関数の可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yHnbZwv6u-df",
        "outputId": "91537874-89d9-4586-a8a3-c221a7f9b626"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(mean_losses_left, label='left')\n",
        "plt.plot(mean_losses_right, label='right')\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4d0aee7b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arKFuiiZvfq7"
      },
      "source": [
        "# 予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw8_eIrPzOwf"
      },
      "source": [
        "def translate_sentence(encoder, decoder_left, decoder_right, sentence, title, device, max_length=50):\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token for token in tokenizer(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, title.init_token)\n",
        "    tokens.append(title.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [title.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs_left = [title.vocab.stoi[\"<sos>\"]]\n",
        "    outputs_right = [title.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for i in range(max_length):\n",
        "        trg_tensor_left = torch.LongTensor(outputs_left).unsqueeze(1).to(device)\n",
        "        trg_tensor_right = torch.LongTensor(outputs_right).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            memory = encoder(sentence_tensor) # これfor文の外でもいい気がする\n",
        "            output_left = decoder_left(trg_tensor_left, memory)\n",
        "            output_right = decoder_right(trg_tensor_right, memory)\n",
        "\n",
        "        best_guess_left = output_left.argmax(2)[-1, :].item()\n",
        "        best_guess_right = output_right.argmax(2)[-1, :].item()\n",
        "        outputs_left.append(best_guess_left)\n",
        "        outputs_right.append(best_guess_right)\n",
        "\n",
        "        if best_guess_right == title.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence_right = [title.vocab.itos[idx] for idx in outputs_right]\n",
        "    translated_sentence_left = [title.vocab.itos[idx] for idx in outputs_left]\n",
        "    # remove start token\n",
        "    return translated_sentence_left[1:], translated_sentence_right[1:]"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuu7fwi-0CNh"
      },
      "source": [
        "sentence = \"▶︎質疑応答◀︎ヒトは神を創った、自分の愚かさを正当化するために\""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lfd6qrfvhVq"
      },
      "source": [
        "translated_sentence = translate_sentence(\n",
        "        encoder, decoder_left, decoder_right, sentence, title, device, max_length=50\n",
        "    )\n",
        "print(f\"Translated example sentence: \\n {translated_sentence}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8qRFfL-kvk1"
      },
      "source": [
        "# Decoderだけの場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgotUcb4kw6Y"
      },
      "source": [
        "def title2title(encoder, decoder, sentence, title, device, max_length=50):\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token for token in tokenizer(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, title.init_token)\n",
        "    tokens.append(title.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [title.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs = [title.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for i in range(max_length):\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            memory = encoder(sentence_tensor) # これfor文の外でもいい気がする\n",
        "            output = decoder(trg_tensor, memory)\n",
        "\n",
        "        best_guess = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfBu7SGDk9FC",
        "outputId": "40e288ea-3574-45d7-ae9a-2a1013ed7927"
      },
      "source": [
        "for batch_idx, batch in enumerate(train_iterator):\n",
        "    print(batch.title[:, 1])\n",
        "    test = batch.title[:, 1]\n",
        "\n",
        "sentence = []\n",
        "for i in test:\n",
        "    s = title.vocab.itos[i]\n",
        "    sentence.append(s)\n",
        "sentence.remove('<sos>')\n",
        "sentence.remove('<eos>')\n",
        "sentence.remove('<pad>')\n",
        "sentence = [s for s in sentence if s != '<pad>']\n",
        "sentence = ''.join(sentence)\n",
        "print(sentence)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  2,  98,   5, 103, 128,  12,  15,  18, 117,  51,  16, 112,  19,  27,\n",
            "         17, 107,  12,  15,  95,   5,   4,  11,  10,   9,  42,   6,   3,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1], device='cuda:0')\n",
            "大衆は常に間違っている。特にあなたが成功したいと思っている場合は【質疑応答#35】\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NrLwczsle52",
        "outputId": "bb4b83a2-3e37-4ce2-94ac-45dc49004bd3"
      },
      "source": [
        "title2title(encoder, decoder, sentence, title, device)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 78,\n",
              " 72,\n",
              " 127,\n",
              " 75,\n",
              " 13,\n",
              " 120,\n",
              " 17,\n",
              " 118,\n",
              " 8,\n",
              " 130,\n",
              " 56,\n",
              " 18,\n",
              " 105,\n",
              " 16,\n",
              " 52,\n",
              " 65,\n",
              " 92,\n",
              " 5,\n",
              " 54,\n",
              " 33,\n",
              " 7,\n",
              " 86,\n",
              " 18,\n",
              " 58,\n",
              " 76,\n",
              " 5,\n",
              " 33,\n",
              " 7,\n",
              " 85,\n",
              " 20,\n",
              " 4,\n",
              " 11,\n",
              " 10,\n",
              " 9,\n",
              " 41,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    }
  ]
}