{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enc-Dec[Transformer].ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eM0ZRpl-2TSo",
        "g3MT2gJW7EGf",
        "BQa1ZUCjOJkJ",
        "SR9hPyFAZhU9",
        "arKFuiiZvfq7"
      ],
      "mount_file_id": "1kS9-i3gpQJ5plrCFBtDUr7MTyu_es52K",
      "authorship_tag": "ABX9TyMxgpY8jfXUFhdVvYnNY8A7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokoshin0720/ml-tutorials/blob/main/Enc_Dec%5BTransformer%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM0ZRpl-2TSo"
      },
      "source": [
        "# インストール -> 再起動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwAiDqgwzdof",
        "outputId": "ab5d640f-adec-431f-bc0b-a8e1cd9cdbf5"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "\n",
        "!pip install torchtext==0.8.0\n",
        "!pip install torch==1.7.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "0 upgraded, 21 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 3,877 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Fetched 3,877 kB in 3s (1,271 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "0 packages upgraded, 11 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.3 MB in 5s (5,866 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 161231 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "                            \n",
            "Collecting mecab-python3==0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
            "  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python3: filename=mecab_python3-0.7-cp37-cp37m-linux_x86_64.whl size=156586 sha256=c1fc6727fe676ab6841b76e4674d6e9889e5769b648104dd5b763de435e41303\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
            "Successfully built mecab-python3\n",
            "Installing collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.7\n",
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed torchtext-0.8.0\n",
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 25kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3MT2gJW7EGf"
      },
      "source": [
        "# 必要なモジュールのimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttvyQXX65TbP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext import data\n",
        "from torchtext.data import Field\n",
        "import MeCab"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEvKfdq7LCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0a50b8-d79d-4b5c-b3e1-3ef44112d923"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZXf7Q_mgVtz"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku5y6vvJg0FE"
      },
      "source": [
        "Mecabで分かち書き"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRVBdRj9gzTL"
      },
      "source": [
        "def tokenizer(text):\n",
        "    return m.parse(text).split()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftf97h1LpWVo"
      },
      "source": [
        "strの文を入力して、予測結果のlistを返す\n",
        "\n",
        "-> rightではなくtitleのvocabを使う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgotUcb4kw6Y"
      },
      "source": [
        "def title2right(encoder, decoder_right, sentence, device, max_length):\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token for token in tokenizer(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, title.init_token)\n",
        "    tokens.append(title.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [title.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device) # Encoderへの入力文\n",
        "\n",
        "    outputs = [title.vocab.stoi[\"<sos>\"]] # 予測結果を格納するlist\n",
        "\n",
        "    for i in range(max_length):\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            memory = encoder(sentence_tensor) # これfor文の外でもいい気がする\n",
        "            output = decoder_right(trg_tensor, memory)\n",
        "\n",
        "        best_guess = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        if best_guess == title.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    # outputを文字列に変換\n",
        "    outputs_str = []\n",
        "    for token_num in outputs:\n",
        "        tkn = title.vocab.itos[token_num]\n",
        "        outputs_str.append(tkn)\n",
        "\n",
        "    return outputs, outputs_str[1:-1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtP9P5ojgcKc"
      },
      "source": [
        "バッチからタイトルのリスト（文字列&数字）を返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r8wzkGCgbqW"
      },
      "source": [
        "def batch2title(batch, batch_size):\n",
        "    sentence_list_int = []\n",
        "    for size in range(batch_size):\n",
        "        sentence_int = batch.right[:, size]\n",
        "        sentence_list_int.append(sentence_int)\n",
        "\n",
        "    sentence_list_str = []\n",
        "    for sentence_int in sentence_list_int:\n",
        "        sentence = []\n",
        "        for i in sentence_int:\n",
        "            s = right.vocab.itos[i]\n",
        "            sentence.append(s)\n",
        "        sentence.remove('<sos>')\n",
        "        sentence.remove('<eos>')\n",
        "        sentence = [s for s in sentence if s != '<pad>']\n",
        "        # sentence = ''.join(sentence)\n",
        "        sentence_list_str.append(sentence)\n",
        "\n",
        "    return sentence_list_str, sentence_list_int"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLO15IsEWCW1"
      },
      "source": [
        "batch_rightを入力すると、title_vocabに変換する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-f07MPuWB2u"
      },
      "source": [
        "def right_vocab2title_vocab(target_right, device):\n",
        "    batch_right = []\n",
        "    for row in target_right:\n",
        "        row = row.tolist()\n",
        "        row_list = []\n",
        "        for word in row:\n",
        "            word = right.vocab.itos[word]\n",
        "            word = title.vocab.stoi[word]\n",
        "            row_list.append(word)\n",
        "        batch_right.append(row_list)\n",
        "    \n",
        "    return torch.Tensor(batch_right).to(torch.int64).to(device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boWTbMuegp6o"
      },
      "source": [
        "bleuスコアを計算する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8VBr92Jgpsm",
        "outputId": "6c0fd17a-6c32-425d-9b72-82355860c4f1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import bleu_score\n",
        "\n",
        "def cal_accuracy(raw, pred):\n",
        "    pred = [pred]\n",
        "    score = bleu_score.sentence_bleu(pred, raw)\n",
        "    return score"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQa1ZUCjOJkJ"
      },
      "source": [
        "# データの前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_S-nRnq_G4",
        "outputId": "6e79e562-4cf5-4de8-878f-b9ebb990c25f"
      },
      "source": [
        "m = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "# Fieldオブジェクトの作成\n",
        "title = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "right = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "left = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "# CSVファイルを読み込み、TabularDatasetオブジェクトを作成\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = \"/content/drive/MyDrive/data/nakazawa_lab/youtuber_title/\",\n",
        "    train = \"youtube_test.csv\",\n",
        "    test = \"youtube_test.csv\",\n",
        "    format=\"csv\",\n",
        "    fields=[('title', title), ('right', right), ('left', left)]\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_SCdj7e7dJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c11725-45ac-4e75-8a8a-632429832e42"
      },
      "source": [
        "for example in train_data[:3]:\n",
        "    print(example.title)\n",
        "    print(example.right)\n",
        "    print(example.left)\n",
        "    print(\"=\"*30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeff', '結果', 'を', '出す', '前', 'に', '豪語', 'する', '人', 'は', '、', 'たいてい', '小物', '【', '質疑', '応答', '#', '36', '】']\n",
            "['、', 'たいてい', '小物', '【', '質疑', '応答', '#', '36', '】']\n",
            "['、', 'は', '人', 'する', '豪語', 'に', '前', '出す', 'を', '結果']\n",
            "==============================\n",
            "['人生', '変わる', '7', 'つ', 'の', '時間', '感覚', '改善', 'ツール']\n",
            "['時間', '感覚', '改善', 'ツール']\n",
            "['時間', 'の', 'つ', '7', '変わる', '人生']\n",
            "==============================\n",
            "['大衆', 'は', '常に', '間違っ', 'て', 'いる', '。', '特に', 'あなた', 'が', '成功', 'し', 'たい', 'と', '思っ', 'て', 'いる', '場合', 'は', '【', '質疑', '応答', '#', '35', '】']\n",
            "['て', 'いる', '。', '特に', 'あなた', 'が', '成功', 'し', 'たい', 'と', '思っ', 'て', 'いる', '場合', 'は', '【', '質疑', '応答', '#', '35', '】']\n",
            "['て', '間違っ', '常に', 'は', '大衆']\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gmvIbFU9rTT"
      },
      "source": [
        "単語辞書の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAXPGTcj9sds"
      },
      "source": [
        "title.build_vocab(train_data)\n",
        "right.build_vocab(train_data)\n",
        "left.build_vocab(train_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7KCicPgOSUm"
      },
      "source": [
        "# Transformerモデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk62jCiuCjCd"
      },
      "source": [
        "Encoder -> memoryを返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr89_Yy_Ca0d"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=forward_expansion,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        encoder_norm = nn.LayerNorm(normalized_shape=embedding_size)\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer=encoder_layer,\n",
        "            num_layers=num_encoder_layers,\n",
        "            norm=encoder_norm\n",
        "        )\n",
        "\n",
        "        self.device = device\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_seq_length, N = src.shape\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        memory = self.encoder(\n",
        "            src=embed_src,\n",
        "            src_key_padding_mask=src_padding_mask\n",
        "        )\n",
        "        return memory\n",
        "\n",
        "        def make_src_mask(self, src):\n",
        "            src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "            return src_mask.to(self.device)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "        return src_mask.to(self.device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7y03Y2iD7GG"
      },
      "source": [
        "Decoder -> memoryを受け取って、生成結果を返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6NweVFND6_F"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        trg_vocab_size,\n",
        "        num_heads,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=embedding_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=forward_expansion,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        decoder_norm = nn.LayerNorm(normalized_shape=embedding_size)\n",
        "\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            decoder_layer=decoder_layer,\n",
        "            num_layers=num_decoder_layers,\n",
        "            norm=decoder_norm\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, memory):\n",
        "        trg_seq_length, N = trg.shape\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "        trg_mask = self.generate_square_subsequent_mask(trg_seq_length).to(self.device)\n",
        "\n",
        "        out = self.decoder(\n",
        "            tgt=embed_trg,\n",
        "            memory=memory,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        return out\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR9hPyFAZhU9"
      },
      "source": [
        "# ハイパーパラメータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLU_27kzZjoB"
      },
      "source": [
        "num_epochs = 50\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAd7zkX0Zkvx"
      },
      "source": [
        "src_vocab_size = len(title.vocab)\n",
        "trg_vocab_size = len(title.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 6\n",
        "num_decoder_layers = 6\n",
        "dropout = 0.10\n",
        "max_len = 50\n",
        "forward_expansion = 4\n",
        "src_pad_idx = 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvbf5NzJZ3ys"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpNqN2nXZ6Jq",
        "outputId": "bd436f64-e4b5-429b-a9a2-8833d1c6fcf3"
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "        (train_data, test_data),\n",
        "        batch_size=batch_size,\n",
        "        sort_within_batch=True,\n",
        "        sort_key=lambda x: len(x.title),\n",
        "        device=device,\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKeggt1TFC1B"
      },
      "source": [
        "モデルの宣言"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3lleaAJFEcd"
      },
      "source": [
        "encoder = Encoder(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder_right = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynez4FnaFeNo"
      },
      "source": [
        "optimizerとloss関数の宣言"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCe3OqdbSUt"
      },
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_right_optimizer = optim.Adam(decoder_right.parameters(), lr=learning_rate)\n",
        "\n",
        "encoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    encoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_right_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_right_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "\n",
        "pad_idx = title.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGCDg6IfGGC-"
      },
      "source": [
        "学習開始(Encoder-Decoderモデル)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGX4ZjWPGI00"
      },
      "source": [
        "mean_losses_right = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"=\"*30)\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    losses_right = []\n",
        "\n",
        "    encoder.train()\n",
        "    decoder_right.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        '''\n",
        "        入力データ\n",
        "        '''\n",
        "        inp_data = batch.title.to(device)\n",
        "        target_right = batch.right.to(device)\n",
        "        target_right = right_vocab2title_vocab(target_right, device) # title.vocab辞書に変更\n",
        "\n",
        "        '''\n",
        "        encoderとdecoderに渡す\n",
        "        '''\n",
        "        memory = encoder(inp_data)\n",
        "        output_right = decoder_right(target_right[:-1, :], memory)\n",
        "\n",
        "        '''\n",
        "        勾配の初期化\n",
        "        '''\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_right_optimizer.zero_grad()\n",
        "\n",
        "        '''\n",
        "        outputの形式を変更（loss計算用）\n",
        "        '''\n",
        "        output_right = output_right.reshape(-1, output_right.shape[2])\n",
        "        target_right = target_right[1:].reshape(-1)\n",
        "\n",
        "        '''\n",
        "        loss計算\n",
        "        '''\n",
        "        loss_right = criterion(output_right, target_right)\n",
        "        losses_right.append(loss_right.item())\n",
        "\n",
        "        '''\n",
        "        誤差逆伝搬\n",
        "        '''\n",
        "        loss_right.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "        torch.nn.utils.clip_grad_norm_(decoder_right.parameters(), max_norm=1)\n",
        "\n",
        "        '''\n",
        "        重みの更新\n",
        "        '''\n",
        "        encoder_optimizer.step()\n",
        "        decoder_right_optimizer.step()\n",
        "\n",
        "        '''\n",
        "        予測\n",
        "        '''\n",
        "        if batch_idx != 0: continue\n",
        "        encoder.eval()\n",
        "        decoder_right.eval()\n",
        "        \n",
        "        sentence_list_str, sentence_list_int = batch2title(batch, batch_size=12) # right.vocab辞書のstrとintを格納\n",
        "        batch_score = 0\n",
        "        \n",
        "        for sentence_str in sentence_list_str:\n",
        "            pred_num, pred_str = title2right(encoder, decoder_right, sentence_str, device, max_len) # encoderへの入力文を入れて、予測する\n",
        "            score = cal_accuracy(sentence_str, pred_str)\n",
        "            batch_score += score\n",
        "            print(\"入力文： \", sentence_str)\n",
        "            print(\"予測文：　\", pred_str)\n",
        "        print(\"正解率： \", batch_score / batch_size)\n",
        "\n",
        "    '''\n",
        "    バッチの平均ロスを計算\n",
        "    '''\n",
        "    mean_loss_right = sum(losses_right) / len(losses_right)\n",
        "\n",
        "    '''\n",
        "    スケジューラー（学習率の調整）\n",
        "    '''\n",
        "    encoder_scheduler.step(mean_loss_right)\n",
        "    decoder_right_scheduler.step(mean_loss_right)\n",
        "    '''\n",
        "    loss append\n",
        "    '''\n",
        "    mean_losses_right.append(mean_loss_right)\n",
        "    print(\"right: \", mean_loss_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiftllNUu8sg"
      },
      "source": [
        "損失関数の可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yHnbZwv6u-df",
        "outputId": "f3d06e9a-f26f-4bff-8599-bbc0ae060e31"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(mean_losses_right, label='right')\n",
        "plt.legend()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f814f3b0750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arKFuiiZvfq7"
      },
      "source": [
        "# 予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw8_eIrPzOwf"
      },
      "source": [
        "def translate_sentence(encoder, decoder_left, decoder_right, sentence, title, device, max_length=50):\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token for token in tokenizer(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, title.init_token)\n",
        "    tokens.append(title.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [title.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs_left = [title.vocab.stoi[\"<sos>\"]]\n",
        "    outputs_right = [title.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for i in range(max_length):\n",
        "        trg_tensor_left = torch.LongTensor(outputs_left).unsqueeze(1).to(device)\n",
        "        trg_tensor_right = torch.LongTensor(outputs_right).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            memory = encoder(sentence_tensor) # これfor文の外でもいい気がする\n",
        "            output_left = decoder_left(trg_tensor_left, memory)\n",
        "            output_right = decoder_right(trg_tensor_right, memory)\n",
        "\n",
        "        best_guess_left = output_left.argmax(2)[-1, :].item()\n",
        "        best_guess_right = output_right.argmax(2)[-1, :].item()\n",
        "        outputs_left.append(best_guess_left)\n",
        "        outputs_right.append(best_guess_right)\n",
        "\n",
        "        if best_guess_right == title.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence_right = [title.vocab.itos[idx] for idx in outputs_right]\n",
        "    translated_sentence_left = [title.vocab.itos[idx] for idx in outputs_left]\n",
        "    # remove start token\n",
        "    return translated_sentence_left[1:], translated_sentence_right[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuu7fwi-0CNh"
      },
      "source": [
        "sentence = \"▶︎質疑応答◀︎ヒトは神を創った、自分の愚かさを正当化するために\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lfd6qrfvhVq"
      },
      "source": [
        "translated_sentence = translate_sentence(\n",
        "        encoder, decoder_left, decoder_right, sentence, title, device, max_length=50\n",
        "    )\n",
        "print(f\"Translated example sentence: \\n {translated_sentence}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8qRFfL-kvk1"
      },
      "source": [
        "# Decoderだけの場合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ViPgwohDvUR"
      },
      "source": [
        "データ定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-uUBhV_DvF_",
        "outputId": "c9036485-2b75-49ec-a202-244acf31e74f"
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "        (train_data, test_data),\n",
        "        batch_size=batch_size,\n",
        "        sort_within_batch=True,\n",
        "        sort_key=lambda x: len(x.title),\n",
        "        device=device,\n",
        "        )"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT2hpVJjCgb6"
      },
      "source": [
        "モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKJhtQcvCi_G"
      },
      "source": [
        "encoder = Encoder(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THbw_gnQCjmE"
      },
      "source": [
        "optim定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xg1RCTCmJ3"
      },
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "encoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    encoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "pad_idx = 0\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOd9iCKnCmnu"
      },
      "source": [
        "学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0m8HMr-Cdgl",
        "outputId": "326ede2c-1f84-485b-824e-17f7e7fdfba0"
      },
      "source": [
        "mean_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    losses = []\n",
        "    output2bests = []\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        '''\n",
        "        入力データ\n",
        "        '''\n",
        "        inp_data = batch.title.to(device)\n",
        "        target = batch.title.to(device)\n",
        "\n",
        "        '''\n",
        "        encoderとdecoderに渡す\n",
        "        '''\n",
        "        memory = encoder(inp_data)\n",
        "        output = decoder(target[:-1, :], memory)\n",
        "\n",
        "        '''\n",
        "        勾配の初期化\n",
        "        '''\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        '''\n",
        "        loss計算\n",
        "        '''\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        '''\n",
        "        誤差逆伝搬\n",
        "        '''\n",
        "        loss.backward(retain_graph=True)\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "\n",
        "        '''\n",
        "        重みの更新\n",
        "        '''\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        '''\n",
        "        予測\n",
        "        '''\n",
        "        if batch_idx != 0: continue\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        sentence_list_str, sentence_list_int = batch2title(batch, title, batch_size)\n",
        "        batch_score = 0\n",
        "        for sentence_str, sentence_int in zip(sentence_list_str, sentence_list_int):\n",
        "            pred_num, pred_str = title2title(encoder, decoder, sentence_str, title, device, max_len)\n",
        "            score = cal_accuracy(sentence_str, pred_str)\n",
        "            batch_score += score\n",
        "        print(sentence_str)\n",
        "        print(pred_str)\n",
        "        print(\"正解率： \", batch_score / batch_size)\n",
        "\n",
        "    '''\n",
        "    バッチの平均ロスを計算\n",
        "    '''\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "\n",
        "    '''\n",
        "    スケジューラー（学習率の調整）\n",
        "    '''\n",
        "    decoder_scheduler.step(mean_loss)\n",
        "    '''\n",
        "    loss append\n",
        "    '''\n",
        "    mean_losses.append(mean_loss)\n",
        "    print(\"loss: \", mean_loss)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['【', 'GACKT×', '中田', '敦彦', '】', '海外', '移住', '・', '生き方', '・', 'ビジネス', '・', 'ボランティア', 'を', '語る']\n",
            "['【', 'GACKT×', '敦彦', '敦彦', '海外', '海外', '海外', '・', '生き方', '・', 'ビジネス', '・', 'ボランティア', 'を', 'を', '語る']\n",
            "正解率：  0.6473788017037222\n",
            "loss:  1.139825604737751\n",
            "[Epoch 1 / 50]\n",
            "['Vlog', '【', 'フィルム', 'カメラ', 'で', 'あそぼ', 'う', '！', '！】～', 'ニコン', 'FE', '～']\n",
            "['【', 'フィルム', 'フィルム', 'カメラ', 'で', 'あそぼ', 'う', '！', '！】～', 'ニコン', '～', '～']\n",
            "正解率：  0.7166896768115434\n",
            "loss:  1.3592447146536812\n",
            "[Epoch 2 / 50]\n",
            "['1', '億', '円', '寄付', 'し', 'て', 'コロナ', '医療', '支援', '募金', 'を', '立ち', '上げ', 'まし', 'た', '。', '僕', 'と', '一緒', 'に', '募金', 'し', 'て', '命', 'を', '守る', '人', 'を', '支え', 'ませ', 'ん', 'か', '？']\n",
            "['1', '億', '円', '寄付', 'し', 'て', 'コロナ', 'コロナ', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '募金', 'と', '募金', '募金', 'と', '一緒', 'と', 'ませ', 'と', 'ませ', 'ん', 'ん', 'ん', 'ん', 'ませ', 'ん', 'ん']\n",
            "正解率：  0.19185659814143927\n",
            "loss:  4.450397090306358\n",
            "[Epoch 3 / 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['【', 'ボタン', '式', '/', 'Bluetooth', '搭載', 'の', 'MP', '3', 'プレーヤー', '】', '音質', '良し', '、', '画面', '良し', '、', '使い', 'やす', 'さ', '良し', '、', '機能', '良し', '！', '！']\n",
            "['良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し']\n",
            "正解率：  0.19671135341159457\n",
            "loss:  3.84639545092507\n",
            "[Epoch 4 / 50]\n",
            "['【', 'コンビニ', '新', '商品', '】', 'JUICY', 'DROP', 'GUMMIES', '！', 'レビュー', '！', 'ジューシードロップグミ', 'Japanese', 'Sweets', 'Review', '【', 'セブン', '】', '【#', '49', '】']\n",
            "['！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！']\n",
            "正解率：  0.13478710382277284\n",
            "loss:  3.6983810757833813\n",
            "[Epoch 5 / 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['【', '万', '乳', '引力', '】', '男', 'は', 'なぜ', '【', '巨乳', 'に', '惹か', 'れる', 'の', 'か', '】']\n",
            "['【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【']\n",
            "正解率：  0.11877659468292077\n",
            "loss:  3.598333169543554\n",
            "[Epoch 6 / 50]\n",
            "['幸せ', 'な', '結婚', 'の', '【', '絶対', '条件', '】', 'が', '判明', '【', 'カリフォルニア', '大学', '最新', '研究', '】']\n",
            "['判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明']\n",
            "正解率：  0.1083322774196349\n",
            "loss:  3.2168736552435253\n",
            "[Epoch 7 / 50]\n",
            "['何', 'を', 'やっ', 'て', 'も', '【', '続か', 'ない', '人', '】', 'の', '問題', '点', 'TOP', '5']\n",
            "['も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も']\n",
            "正解率：  0.3699145920495941\n",
            "loss:  2.696746580184452\n",
            "[Epoch 8 / 50]\n",
            "['【', '兄弟', '対決', '】', 'ヒカキン', 'vs', 'セイ', 'キン', '声優', 'バトル', '！', '【', 'アプモン', '】']\n",
            "['【', '兄弟', '兄弟', '】', 'ヒカキン', 'vs', 'vs', '！', 'アプモン', 'バトル', 'アプモン', 'アプモン', 'アプモン', 'アプモン']\n",
            "正解率：  0.2779280964650152\n",
            "loss:  1.9423562080141097\n",
            "[Epoch 9 / 50]\n",
            "['【', 'ランキング', '】', 'ヒカキン', 'か', '゙', 'ハマっ', 'てる', 'コンヒ', '゙', 'ニ', 'お', 'やつ', 'トップ', '３', '【', '2020', '年', '5', '月', '編', '】']\n",
            "['【', 'ランキング', '】', 'ヒカキン', 'か', '゙', '゙', 'てる', 'てる', '゙', 'ニ', 'トップ', 'トップ', 'やつ', '5', 'トップ', 'トップ', '5', '【', '】', '【', '【', '】', '【', '】', '【', '】']\n",
            "正解率：  0.18436056509092486\n",
            "Epoch    60: reducing learning rate of group 0 to 3.0000e-05.\n",
            "loss:  1.8645827476940458\n",
            "[Epoch 10 / 50]\n",
            "['【', '448', '台', '】', '宇宙', '一', 'クレーン', 'ゲーム', 'か', '゙', '多い', '超', '巨大', 'ケ', '゙', 'ーセン', 'て', '゙', '景品', '取り', 'まくる', 'w', '【', 'UFO', 'キャッチャー', '】']\n",
            "['【', '448', '台', '】', '一', '一', 'ゲーム', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', 'w']\n",
            "正解率：  0.27156697628217846\n",
            "loss:  1.8972516476161896\n",
            "[Epoch 11 / 50]\n",
            "['【', 'ロス', 'チャイルド', '家', '②】', 'ユダヤ', '人', '大', '富豪', 'にまつわる', '陰謀', '論', 'の', '真実']\n",
            "['【', 'ロス', 'チャイルド', '家', '②】', 'ユダヤ', '人', '大', '陰謀', '陰謀', '陰謀', '陰謀', '陰謀', '陰謀']\n",
            "正解率：  0.5447980182116169\n",
            "loss:  1.283098947907251\n",
            "[Epoch 12 / 50]\n",
            "['【', 'ネットワーク', 'ビジネス', '】', 'について', '話し', 'ます']\n",
            "['【', 'ネットワーク', 'ビジネス', '】', 'について', '話し', 'ます']\n",
            "正解率：  0.862852168247238\n",
            "loss:  1.1439066902985648\n",
            "[Epoch 13 / 50]\n",
            "['好か', 'れる', 'お', '世辞', '、', '嫌わ', 'れる', 'お', '世辞']\n",
            "['好か', 'れる', 'お', '世辞', '、', '嫌わ', 'れる', 'お', '世辞']\n",
            "正解率：  0.854033503313369\n",
            "loss:  1.0522790248431857\n",
            "[Epoch 14 / 50]\n",
            "['【', '最高', 'の', '睡眠', '②】', '新型', 'コロナ', 'ウイルス', 'から', '身', 'を', '守る', '安眠', '法']\n",
            "['【', '最高', 'の', '睡眠', '②】', '新型', 'コロナ', 'ウイルス', 'から', '守る', '守る', '守る', '安眠', '安眠']\n",
            "正解率：  0.5291990132161716\n",
            "loss:  0.965026266281567\n",
            "[Epoch 15 / 50]\n",
            "['【', 'USB', 'マイク', 'の', '完成', '形', '】', 'HyperX', 'の', 'QuadCast', 'を', '開封', 'レビュー', '！']\n",
            "['【', 'USB', 'マイク', 'の', '完成', '形', '】', 'の', 'の', '開封', '開封', '開封', '開封', '開封']\n",
            "正解率：  0.5762667054602376\n",
            "loss:  0.8879166796566949\n",
            "[Epoch 16 / 50]\n",
            "['即', '完売', 'の', 'スプラトゥーン', '2', 'nanaco', 'フィギュア', 'が', 'ｷﾀ', '━(', 'ﾟ', '∀', 'ﾟ', ')━！', 'ヒカキン', 'nanaco', 'デビュー', '!']\n",
            "['即', '完売', 'の', 'スプラトゥーン', '2', 'nanaco', 'フィギュア', 'が', 'ｷﾀ', 'ｷﾀ', 'ﾟ', 'ﾟ', 'ﾟ', 'ﾟ', 'ヒカキン', 'nanaco', '!', '!']\n",
            "正解率：  0.5275229197047003\n",
            "loss:  0.8417252233577153\n",
            "[Epoch 17 / 50]\n",
            "['【', '感動', 'の', '涙', '】', '39', '℃', 'の', '熱', 'で', 'ダウン', 'し', 'た', 'カメラマン', 'の', '兄', 'に', 'お', '粥', '作っ', 'て', '家', 'まで', '持っ', 'て', 'いっ', 'たら', '…']\n",
            "['【', '感動', 'の', '涙', '】', '39', '℃', 'の', 'の', 'で', 'し', 'し', 'た', 'た', 'の', 'お', 'お', 'お', 'お', 'お', 'て']\n",
            "正解率：  0.33701620038097096\n",
            "loss:  0.8325313355714555\n",
            "[Epoch 18 / 50]\n",
            "['【', '繊細', 'さん', 'の', '幸せ', 'リスト', '①】', '繊細', 'さ', 'は', '「', '幸せ', 'を', '感じる', 'ため', '」', 'の', '才能']\n",
            "['【', '繊細', 'さん', 'の', '幸せ', 'リスト', '①】', '繊細', 'さ', 'は', 'は', '幸せ', '幸せ', '感じる', '」', 'を', 'を', 'を', 'の', 'の', 'の', 'の', 'の', 'の', 'の', 'の', 'の']\n",
            "正解率：  0.5036868585736632\n",
            "loss:  0.7768785667324823\n",
            "[Epoch 19 / 50]\n",
            "['いい', '仕事', 'トップ', 'ランキング', '&', 'amp', ';', 'ヤバイ', '仕事', 'ワースト', 'ランキング']\n",
            "['いい', '仕事', 'トップ', 'ランキング', '&', 'amp', ';', '仕事', '仕事', 'ワースト']\n",
            "正解率：  0.7532346210339878\n",
            "loss:  0.8187822761043669\n",
            "[Epoch 20 / 50]\n",
            "['ヒカキン', 'から', '重大', '発表', 'が', 'あり', 'ます']\n",
            "['ヒカキン', 'から', '重大', '発表', 'が', 'あり', 'ます']\n",
            "正解率：  0.8550412659423021\n",
            "loss:  0.7216687417692609\n",
            "[Epoch 21 / 50]\n",
            "['【', 'ドッキリ', '】', '超', 'ヒカキン', '好き', 'な', '女の子', 'の', '家', 'に', 'いる', 'ト', '゙', 'ッキリ', 'し', 'たら', '大変', 'な', 'こと', 'に', 'w', '【', '感動', '】']\n",
            "['【', 'ドッキリ', '】', '超', 'ヒカキン', '好き', 'な', '女の子', 'の', '家', 'に', 'いる', 'ト', 'ト', 'ッキリ', 'し', 'し', 'な', '感動', 'こと', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に']\n",
            "正解率：  0.39466142751882766\n",
            "loss:  0.687292718698108\n",
            "[Epoch 22 / 50]\n",
            "['【', '大麻', '②】〜', '麻薬', 'から', '自分', 'の', '身', 'を', '守る', 'ため', 'の', '授業', '、', '日本', 'の', '大麻', '合法', '化', 'は', 'どう', 'なる', '？', '〜']\n",
            "['【', '大麻', '②】〜', '麻薬', 'から', '自分', 'の', 'の', 'を', '守る', 'ため', 'の', 'の', '、', '日本', 'の', '合法', 'は', 'は', 'は', '？', 'なる']\n",
            "正解率：  0.4514833678634449\n",
            "loss:  0.6936544657699646\n",
            "[Epoch 23 / 50]\n",
            "['【', '初めて', '営業', 'する', '人', '】', '【', '営業', 'が', '苦手', 'な', '人', '】', 'の', 'ため', 'の', '動画', 'です', '^^♪']\n",
            "['【', '初めて', '営業', 'する', '人', '】', '【', '営業', '苦手', '苦手', 'な', '人', 'の', 'の', '動画', '動画', '動画', '^^♪', '^^♪']\n",
            "正解率：  0.6312139446116573\n",
            "loss:  0.6512865813242065\n",
            "[Epoch 24 / 50]\n",
            "['【', 'FIRE', '①】', '最速', 'で', '経済', '的', '自立', 'を', '実現', 'する', '方法', '（', 'Financial', 'Freedom', '）']\n",
            "['【', 'FIRE', '①】', '最速', 'で', '経済', '的', '自立', 'を', '実現', 'する', '方法', '（', '（', '）', '）']\n",
            "正解率：  0.6616129364850433\n",
            "loss:  0.6820392561337304\n",
            "[Epoch 25 / 50]\n",
            "['会計', '払え', 'ず', 'ATM', 'に', '…', '1', '皿', '2500', '円', 'の', 'うに', '牛', 'を', '限界', 'まで', '食べ', '続け', 'たら', '支払い', 'いくら', 'に', 'なる', '？']\n",
            "['会計', '払え', 'ず', 'に', 'に', '…', '1', '皿', '2500', '円', 'の', 'うに', 'うに', 'を', '限界', 'まで', '食べ', '続け', 'たら', 'に', 'なる', 'に', 'なる', 'なる', 'なる', 'なる']\n",
            "正解率：  0.4788387461436041\n",
            "loss:  0.6401862155586954\n",
            "[Epoch 26 / 50]\n",
            "['【', 'USB', 'マイク', 'の', '完成', '形', '】', 'HyperX', 'の', 'QuadCast', 'を', '開封', 'レビュー', '！']\n",
            "['【', 'USB', 'マイク', 'マイク', '完成', '形', '】', 'の', 'の', 'を', 'を', '開封', 'レビュー', '！']\n",
            "正解率：  0.5974731337636443\n",
            "loss:  0.5932616880015721\n",
            "[Epoch 27 / 50]\n",
            "['【', 'いざ', '出陣', '】', '2500', '万', '円', 'で', '購入', 'し', 'た', 'マセラティ', '納車', 'し', 'まし', 'た']\n",
            "['【', 'いざ', '出陣', '】', '2500', '万', '円', 'で', '購入', 'し', 'た', 'マセラティ', '納車', 'し', 'まし', 'た']\n",
            "正解率：  0.7543966879124915\n",
            "loss:  0.5886924154465161\n",
            "[Epoch 28 / 50]\n",
            "['【', '未来', '予測', '①】', '2030', '年', 'の', '世界']\n",
            "['【', '未来', '予測', '①】', '2030', '年', 'の', '世界']\n",
            "正解率：  0.899971865355232\n",
            "loss:  0.5486015718844202\n",
            "[Epoch 29 / 50]\n",
            "['【', '緊急', '事態', '】', 'ヒカル', 'が', '酒', 'で', '完全', 'に', 'ダウン', 'し', 'まし', 'た', '…']\n",
            "['【', '緊急', '事態', '】', 'ヒカル', 'が', '酒', 'で', '完全', 'に', 'ダウン', 'し', 'し', 'た', '…']\n",
            "正解率：  0.8246756285987902\n",
            "loss:  0.5590817273136169\n",
            "[Epoch 30 / 50]\n",
            "['自分', 'を', '疑える', 'の', 'は', '成長', 'できる', '証拠', 'だ', '。', '自分', 'を', '疑わ', 'ない', '人', 'に', '成長', 'は', 'ない', '【', '質疑', '応答', '#', '15', '】']\n",
            "['自分', 'を', '疑える', 'の', 'は', '成長', 'できる', 'だ', 'だ', '。', '自分', 'を', 'ない', 'ない', '人', 'に', '成長', 'は', 'ない', '【', '質疑', '応答', '質疑', '質疑', '質疑', '質疑', '質疑', '#', '#']\n",
            "正解率：  0.522040417321855\n",
            "loss:  0.5422259760754449\n",
            "[Epoch 31 / 50]\n",
            "['【', '食', 'レポ', '】', 'ついに', '辿り', '着', 'い', 'た', '「', '極', 'じゃ', 'が', '」', 'こだわり', 'の', '厳選', 'し', 'お', '味', '食べ', 'て', 'み', 'た', '！', 'カルビー', '！【#', '140', '】']\n",
            "['【', '食', 'レポ', '】', 'ついに', '辿り', '着', 'い', 'た', '「', 'じゃ', 'じゃ', '」', '」', '」', '」', 'し', 'お', 'し', 'て', 'の', 'み', 'み', 'み']\n",
            "正解率：  0.3995960936351299\n",
            "loss:  0.49695848224181977\n",
            "[Epoch 32 / 50]\n",
            "['なぜ', 'YouTube', '初心者', 'は', '【', '100', '本', 'の', '動画', '】', 'が', '作れ', 'ない', 'の', 'か', '？']\n",
            "['なぜ', 'なぜ', 'なぜ', 'なぜ', '100', '100', '本', 'の', '動画', '】', 'が', '作れ', 'ない', 'の', 'か', '？']\n",
            "正解率：  0.8013566710706681\n",
            "loss:  0.511031644507533\n",
            "[Epoch 33 / 50]\n",
            "['【', '東京', '五輪', '延期', '①】', 'オリンピック', 'の', '光', 'と', '影']\n",
            "['【', '東京', '五輪', '延期', '①】', 'オリンピック', 'オリンピック', '光', 'と', '影']\n",
            "正解率：  0.8837506688281637\n",
            "loss:  0.5153299007150862\n",
            "[Epoch 34 / 50]\n",
            "['わが子', 'の', '【', '進路', '選択', '】', 'を', '考え', 'て', 'ます', '..', 'f', '^^;']\n",
            "['わが子', 'の', '【', '進路', '選択', '】', 'を', '考え', 'て', 'ます', '..', '^^;', '^^;']\n",
            "正解率：  0.8684095373797284\n",
            "loss:  0.49406500728357405\n",
            "[Epoch 35 / 50]\n",
            "['【', '毎日', '投稿', '225', '日', '目', '】', '脱サラ', '底辺', '素人', 'YouTuber', 'の', 'チャンネル', '登録', '者', 'は', '増え', 'た', 'の', 'か', '？', '【', '第', '31', '回', '振り返り', '】【#', '225', '】']\n",
            "['【', '毎日', '投稿', '225', '日', '目', '】', '脱サラ', '底辺', '素人', 'YouTuber', 'の', 'チャンネル', '登録', '者', 'は', 'た', 'の', 'か', '【', '【']\n",
            "正解率：  0.49323102036547956\n",
            "loss:  0.5025594556142413\n",
            "[Epoch 36 / 50]\n",
            "['【', '神', 'お', 'やつ', '】', 'DNA', 'を', '修復', 'する', '最強', 'お', 'やつ', 'が', 'こちら']\n",
            "['【', '神', 'お', 'やつ', '】', 'DNA', 'を', '修復', 'する', 'お', 'お', 'やつ', 'が', 'こちら']\n",
            "正解率：  0.7047038059568517\n",
            "loss:  0.4980384053455459\n",
            "[Epoch 37 / 50]\n",
            "['【', 'バビロン', '大', '富豪', 'の', '教え', '②】']\n",
            "['【', 'バビロン', '大', '富豪', 'の', '教え', '②】']\n",
            "正解率：  0.8885551429744107\n",
            "loss:  0.45765529986884856\n",
            "[Epoch 38 / 50]\n",
            "['【', '250', 'ヤード', '越え', '連発', '】', 'プロ', 'の', 'コーチ', 'に', 'ゴルフ', '教わっ', 'たら', '10', '分', 'で', 'ど', '素人', 'ヒカル', 'が', '覚醒', 'し', 'た', 'ww']\n",
            "['【', '250', 'ヤード', '越え', '連発', '】', 'プロ', 'の', 'コーチ', 'に', 'ゴルフ', '教わっ', 'たら', '10', '分', 'で', 'ど', '素人', 'ヒカル', 'ヒカル', '覚醒', 'し', '覚醒', 'し', 'た', 'し', 'た', 'し', 'た', 'ww', 'ww']\n",
            "正解率：  0.633075985031262\n",
            "loss:  0.4581635197594998\n",
            "[Epoch 39 / 50]\n",
            "['【', 'フィルム', 'カメラ', '】', 'で', 'あそぼ', 'う', '！', '！', '【', 'Nikon', 'FG', '】']\n",
            "['【', 'フィルム', 'カメラ', '】', 'で', 'あそぼ', 'う', '！', '！', '【', '【', '】', '】']\n",
            "正解率：  0.9279349980125507\n",
            "loss:  0.4707392334701523\n",
            "[Epoch 40 / 50]\n",
            "['相手', 'の', '考え', 'を', 'ひっくり返す', '絶大', 'な', '効果', 'の', 'ある', 'テクニック', '【', 'Yes', 'and', 'But', '手法', '】']\n",
            "['相手', 'の', '考え', 'を', 'ひっくり返す', '絶大', 'な', '効果', 'の', 'ある', 'テクニック', '【', '【', 'and', '】', '】', '】', '】']\n",
            "正解率：  0.7452953531418408\n",
            "loss:  0.43527336838463\n",
            "[Epoch 41 / 50]\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', '】', 'DELL', 'の', '「', 'AE', '215', '」', 'を', '開封', 'レビュー', '！']\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', '】', 'DELL', 'の', '「', 'AE', '215', '」', '開封', '開封', 'レビュー', '！', '！']\n",
            "正解率：  0.7589736248650787\n",
            "loss:  0.43629666618884555\n",
            "[Epoch 42 / 50]\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', '】', 'DELL', 'の', '「', 'AE', '215', '」', 'を', '開封', 'レビュー', '！']\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', 'スピーカー', '】', '「', 'の', '「', '215', '215', '「', '215', '！']\n",
            "正解率：  0.7495826670206635\n",
            "loss:  0.425080795728025\n",
            "[Epoch 43 / 50]\n",
            "['クレーマー', 'を', '華麗', 'に', '受け流す', '話術', 'TOP', '3']\n",
            "['クレーマー', 'を', '華麗', 'に', '受け流す', '話術', '3', '3']\n",
            "正解率：  0.8831037925726523\n",
            "loss:  0.4208172568016582\n",
            "[Epoch 44 / 50]\n",
            "['ヒカキン', '×', 'マホト', '×', 'PDS', 'で', 'やっ', 'て', '欲しい', 'こと', 'ある', '？', 'リクエスト', '募集', '！']\n",
            "['ヒカキン', '×', 'マホト', '×', 'マホト', 'で', 'やっ', 'て', '欲しい', 'こと', 'ある', '？', 'リクエスト', '募集', '！']\n",
            "正解率：  0.9428338536836932\n",
            "loss:  0.4293424844860084\n",
            "[Epoch 45 / 50]\n",
            "['オジサン', '、', '、', '2', '年', '前', 'から', '【', '白斑', '】', 'です']\n",
            "['オジサン', '、', '、', '2', '年', '前', 'から', '【', '白斑', '】', 'です']\n",
            "正解率：  0.8681381922047234\n",
            "loss:  0.3991850562807586\n",
            "[Epoch 46 / 50]\n",
            "['【', 'ミャンマー', '・', 'クーデター', '①】', 'アウンサンスーチー', 'vs', '国軍', 'の', '権力', '闘争', '（', 'Myanmar', '&#', '39', ';', 's', 'power', 'struggle', '）']\n",
            "['【', 'ミャンマー', '・', 'クーデター', '①】', 'アウンサンスーチー', 'vs', '国軍', 'の', '権力', '闘争', '（', '（', '&#', '39', ';', 's', 'power', '）', '）']\n",
            "正解率：  0.7490428679492412\n",
            "loss:  0.4598053712693472\n",
            "[Epoch 47 / 50]\n",
            "['皮', 'こ', '゙と', 'ハ', '゙', 'ナナ', '食', 'へ', '゙てみた', 'w']\n",
            "['皮', 'こ', '゙と', 'ハ', '゙', 'ナナ', '食', 'へ', '゙てみた', 'w', 'w']\n",
            "正解率：  0.8818093064156703\n",
            "loss:  0.41522617502108455\n",
            "[Epoch 48 / 50]\n",
            "['【', 'コス', 'パ', 'の', '高い', '最新', 'ワイヤレスイヤホン', '】', '1', ',', '999', '円', 'で', 'この', '機能', '、', 'コス', 'パ', '良', 'すぎ', 'です', '!!']\n",
            "['【', 'コス', 'パ', 'の', '高い', '最新', 'ワイヤレスイヤホン', '】', '1', '999', '999', '円', 'で', 'この', '機能', 'コス', 'コス', 'コス', 'すぎ', '!!']\n",
            "正解率：  0.6908198251367937\n",
            "loss:  0.4315577650531417\n",
            "[Epoch 49 / 50]\n",
            "['あなた', 'は', '何', 'タイプ', '？', 'ポケモン', '自己', '分析', 'やっ', 'て', 'み', 'た', '！【#', '7', '】']\n",
            "['あなた', 'は', '何', 'タイプ', '？', 'ポケモン', '自己', '分析', 'やっ', 'て', 'み', 'た', '！【#', '7', '】']\n",
            "正解率：  0.9150435829990526\n",
            "loss:  0.3830832086266979\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}