{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enc-Dec[Transformer].ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eM0ZRpl-2TSo",
        "g3MT2gJW7EGf",
        "BQa1ZUCjOJkJ",
        "SR9hPyFAZhU9",
        "arKFuiiZvfq7"
      ],
      "mount_file_id": "1kS9-i3gpQJ5plrCFBtDUr7MTyu_es52K",
      "authorship_tag": "ABX9TyN7+aOabGlQdEBl7oEpz79+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokoshin0720/ml-tutorials/blob/main/Enc_Dec%5BTransformer%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM0ZRpl-2TSo"
      },
      "source": [
        "# インストール -> 再起動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwAiDqgwzdof",
        "outputId": "3b451c4d-62c3-4590-d84d-9f5ef94dcb73"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "\n",
        "!pip install torchtext==0.8.0\n",
        "!pip install torch==1.7.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "0 upgraded, 21 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 3,877 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Fetched 3,877 kB in 2s (2,186 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "0 packages upgraded, 11 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.3 MB in 3s (10.5 MB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 161231 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "                            \n",
            "Collecting mecab-python3==0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
            "  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python3: filename=mecab_python3-0.7-cp37-cp37m-linux_x86_64.whl size=156588 sha256=18d38c50e2eec85bf28c64ff43d85d8537fdfef2b42b64382f5900d5c524071c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
            "Successfully built mecab-python3\n",
            "Installing collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.7\n",
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed torchtext-0.8.0\n",
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3MT2gJW7EGf"
      },
      "source": [
        "# 必要なモジュールのimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttvyQXX65TbP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext import data\n",
        "from torchtext.data import Field\n",
        "import MeCab"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEvKfdq7LCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84c2157-a100-41bd-ea64-c985160095ee"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZXf7Q_mgVtz"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku5y6vvJg0FE"
      },
      "source": [
        "Mecabで分かち書き"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRVBdRj9gzTL"
      },
      "source": [
        "def tokenizer(text):\n",
        "    return m.parse(text).split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftf97h1LpWVo"
      },
      "source": [
        "strの文を入力して、予測結果のlistを返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgotUcb4kw6Y"
      },
      "source": [
        "def title2title(encoder, decoder, sentence, title, device, max_length):\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token for token in tokenizer(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, title.init_token)\n",
        "    tokens.append(title.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [title.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs = [title.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for i in range(max_length):\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            memory = encoder(sentence_tensor) # これfor文の外でもいい気がする\n",
        "            output = decoder(trg_tensor, memory)\n",
        "\n",
        "        best_guess = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        if best_guess == title.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    outputs_str = []\n",
        "    for token_num in outputs:\n",
        "        tkn = title.vocab.itos[token_num]\n",
        "        outputs_str.append(tkn)\n",
        "\n",
        "    return outputs, outputs_str[1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtP9P5ojgcKc"
      },
      "source": [
        "バッチからタイトルのリスト（文字列&数字）を返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r8wzkGCgbqW"
      },
      "source": [
        "def batch2title(batch, title, batch_size):\n",
        "    sentence_list_int = []\n",
        "    for size in range(batch_size):\n",
        "        sentence_int = batch.title[:, size]\n",
        "        sentence_list_int.append(sentence_int)\n",
        "\n",
        "    sentence_list_str = []\n",
        "    for sentence_int in sentence_list_int:\n",
        "        sentence = []\n",
        "        for i in sentence_int:\n",
        "            s = title.vocab.itos[i]\n",
        "            sentence.append(s)\n",
        "        sentence.remove('<sos>')\n",
        "        sentence.remove('<eos>')\n",
        "        sentence = [s for s in sentence if s != '<pad>']\n",
        "        # sentence = ''.join(sentence)\n",
        "        sentence_list_str.append(sentence)\n",
        "\n",
        "    return sentence_list_str, sentence_list_int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boWTbMuegp6o"
      },
      "source": [
        "bleuスコアを計算する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8VBr92Jgpsm"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import bleu_score\n",
        "\n",
        "def cal_accuracy(raw, pred):\n",
        "    pred = [pred]\n",
        "    score = bleu_score.sentence_bleu(pred, raw)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQa1ZUCjOJkJ"
      },
      "source": [
        "# データの前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_S-nRnq_G4",
        "outputId": "b5cb08bd-5515-4719-8ca2-91c0992e4c10"
      },
      "source": [
        "m = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "# Fieldオブジェクトの作成\n",
        "title = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "right = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "left = data.Field(tokenize=tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "# CSVファイルを読み込み、TabularDatasetオブジェクトを作成\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = \"/content/drive/MyDrive/data/nakazawa_lab/youtuber_title/\",\n",
        "    train = \"youtube_train.csv\",\n",
        "    test = \"youtube_train.csv\",\n",
        "    format=\"csv\",\n",
        "    fields=[('title', title), ('right', right), ('left', left)]\n",
        ")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_SCdj7e7dJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d20f862-12ad-4364-bad9-7540feefd4cb"
      },
      "source": [
        "# for example in train_data[:3]:\n",
        "#     print(example.title)\n",
        "#     print(example.right)\n",
        "#     print(example.left)\n",
        "#     print(\"=\"*30)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeff', '◀', '︎', '質疑', '応答', '▶', '︎', 'ラフ', 'ァ', 'エル', 'さん', 'と', '生放送']\n",
            "['ァ', 'エル', 'さん', 'と', '生放送']\n",
            "['ァ', 'ラフ', '︎', '▶', '応答', '質疑', '︎', '◀']\n",
            "==============================\n",
            "['▶', '︎', '質疑', '応答', '◀', '︎', '苦しみ', 'の', '先', 'に', '幸せ', 'が', 'ある', '。', '苦しい', '中', 'でも', '工夫', 'を', '怠ら', 'なかっ', 'た', '場合', 'は']\n",
            "['工夫', 'を', '怠ら', 'なかっ', 'た', '場合', 'は']\n",
            "['工夫', 'で', 'も', '中', '苦しい', '。', 'ある', 'が', '幸せ', 'に', '先', 'の', '苦しみ', '︎', '◀', '応答', '質疑', '︎', '▶']\n",
            "==============================\n",
            "['▶', '︎', '質疑', '応答', '◀', '︎', 'ヒト', 'は', '神', 'を', '創っ', 'た', '、', '自分', 'の', '愚か', 'さ', 'を', '正当', '化', 'する', 'ため', 'に']\n",
            "['質疑', '応答', '◀', '︎', 'ヒト', 'は', '神', 'を', '創っ', 'た', '、', '自分', 'の', '愚か', 'さ', 'を', '正当', '化', 'する', 'ため', 'に']\n",
            "['質疑', '︎', '▶']\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gmvIbFU9rTT"
      },
      "source": [
        "単語辞書の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAXPGTcj9sds"
      },
      "source": [
        "title.build_vocab(train_data)\n",
        "right.build_vocab(train_data)\n",
        "left.build_vocab(train_data)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7KCicPgOSUm"
      },
      "source": [
        "# Transformerモデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk62jCiuCjCd"
      },
      "source": [
        "Encoder -> memoryを返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr89_Yy_Ca0d"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=forward_expansion,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        encoder_norm = nn.LayerNorm(normalized_shape=embedding_size)\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer=encoder_layer,\n",
        "            num_layers=num_encoder_layers,\n",
        "            norm=encoder_norm\n",
        "        )\n",
        "\n",
        "        self.device = device\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_seq_length, N = src.shape\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        memory = self.encoder(\n",
        "            src=embed_src,\n",
        "            src_key_padding_mask=src_padding_mask\n",
        "        )\n",
        "        return memory\n",
        "\n",
        "        def make_src_mask(self, src):\n",
        "            src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "            return src_mask.to(self.device)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "        return src_mask.to(self.device)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7y03Y2iD7GG"
      },
      "source": [
        "Decoder -> memoryを受け取って、生成結果を返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6NweVFND6_F"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        trg_vocab_size,\n",
        "        num_heads,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=embedding_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=forward_expansion,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        decoder_norm = nn.LayerNorm(normalized_shape=embedding_size)\n",
        "\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            decoder_layer=decoder_layer,\n",
        "            num_layers=num_decoder_layers,\n",
        "            norm=decoder_norm\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, memory):\n",
        "        trg_seq_length, N = trg.shape\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "        trg_mask = self.generate_square_subsequent_mask(trg_seq_length).to(self.device)\n",
        "\n",
        "        out = self.decoder(\n",
        "            tgt=embed_trg,\n",
        "            memory=memory,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        return out\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR9hPyFAZhU9"
      },
      "source": [
        "# ハイパーパラメータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLU_27kzZjoB"
      },
      "source": [
        "num_epochs = 50\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAd7zkX0Zkvx"
      },
      "source": [
        "src_vocab_size = len(title.vocab)\n",
        "trg_vocab_size = len(title.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 6\n",
        "num_decoder_layers = 6\n",
        "dropout = 0.10\n",
        "max_len = 50\n",
        "forward_expansion = 4\n",
        "src_pad_idx = 0"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvbf5NzJZ3ys"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpNqN2nXZ6Jq",
        "outputId": "1debe293-764b-4200-c3b0-8a67b9d70a40"
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "        (train_data, test_data),\n",
        "        batch_size=batch_size,\n",
        "        sort_within_batch=True,\n",
        "        sort_key=lambda x: len(x.title),\n",
        "        device=device,\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKeggt1TFC1B"
      },
      "source": [
        "モデルの宣言"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3lleaAJFEcd"
      },
      "source": [
        "encoder = Encoder(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder_left = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder_right = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynez4FnaFeNo"
      },
      "source": [
        "optimizerとloss関数の宣言"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCe3OqdbSUt"
      },
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_left_optimizer = optim.Adam(decoder_left.parameters(), lr=learning_rate)\n",
        "decoder_right_optimizer = optim.Adam(decoder_right.parameters(), lr=learning_rate)\n",
        "\n",
        "encoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    encoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_left_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_left_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_right_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_right_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "\n",
        "pad_idx = 0\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGCDg6IfGGC-"
      },
      "source": [
        "学習開始(Encoder-Decoderモデル)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGX4ZjWPGI00"
      },
      "source": [
        "mean_losses_left = []\n",
        "mean_losses_right = []\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    losses_left = []\n",
        "    losses_right = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        '''\n",
        "        入力データ\n",
        "        '''\n",
        "        inp_data = batch.title.to(device)\n",
        "        target_left = batch.left.to(device)\n",
        "        target_right = batch.right.to(device)\n",
        "\n",
        "        '''\n",
        "        encoderとdecoderに渡す\n",
        "        '''\n",
        "        memory = encoder(inp_data)\n",
        "        output_left = decoder_left(target_left[:-1, :], memory)\n",
        "        output_right = decoder_right(target_right[:-1, :], memory)\n",
        "\n",
        "        '''\n",
        "        outputの形式を変更\n",
        "        '''\n",
        "        output_left = output_left.reshape(-1, output_left.shape[2])\n",
        "        target_left = target_left[1:].reshape(-1)\n",
        "        output_right = output_right.reshape(-1, output_right.shape[2])\n",
        "        target_right = target_right[1:].reshape(-1)\n",
        "\n",
        "        '''\n",
        "        勾配の初期化\n",
        "        '''\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_left_optimizer.zero_grad()\n",
        "        decoder_right_optimizer.zero_grad()\n",
        "\n",
        "        '''\n",
        "        loss計算\n",
        "        '''\n",
        "        loss_left = criterion(output_left, target_left)\n",
        "        loss_right = criterion(output_right, target_right)\n",
        "        losses_left.append(loss_left.item())\n",
        "        losses_right.append(loss_right.item())\n",
        "\n",
        "        '''\n",
        "        誤差逆伝搬\n",
        "        '''\n",
        "        loss_left.backward(retain_graph=True)\n",
        "        loss_right.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "        torch.nn.utils.clip_grad_norm_(decoder_left.parameters(), max_norm=1)\n",
        "        torch.nn.utils.clip_grad_norm_(decoder_right.parameters(), max_norm=1)\n",
        "\n",
        "        '''\n",
        "        重みの更新\n",
        "        '''\n",
        "        encoder_optimizer.step()\n",
        "        decoder_left_optimizer.step()\n",
        "        decoder_right_optimizer.step()\n",
        "\n",
        "    '''\n",
        "    バッチの平均ロスを計算\n",
        "    '''\n",
        "    mean_loss_left = sum(losses_left) / len(losses_left)\n",
        "    mean_loss_right = sum(losses_right) / len(losses_right)\n",
        "\n",
        "    '''\n",
        "    スケジューラー（学習率の調整）\n",
        "    '''\n",
        "    decoder_left_scheduler.step(mean_loss_left)\n",
        "    decoder_right_scheduler.step(mean_loss_right)\n",
        "    '''\n",
        "    loss append\n",
        "    '''\n",
        "    mean_losses_left.append(mean_loss_left)\n",
        "    mean_losses_right.append(mean_loss_right)\n",
        "    print(\"left: \", mean_loss_left)\n",
        "    print(\"right: \", mean_loss_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiftllNUu8sg"
      },
      "source": [
        "損失関数の可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yHnbZwv6u-df",
        "outputId": "d4b1b2d4-be6e-4d85-fea2-63f23ebc972a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(mean_losses_left, label='left')\n",
        "plt.plot(mean_losses_right, label='right')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4c67e45050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASUklEQVR4nO3dfYydZZnH8e+1LXZUum0p5UWGMlWQpVDCy6FAIAQE+kKkJdjdLZjQ7GoqWflDjcaybHgpmvDmYgiypFGSxohUIGrBKi0IkfAHdIoQbRGnlBqmgpSCrLOkQHev/WMe3MPsKZ2Zc2ZOp/f3k5zM89zP9Zxz3Z1kfvM89+mZyEwkSeX6m3Y3IElqL4NAkgpnEEhS4QwCSSqcQSBJhRvf7gaG48ADD8yurq52tyFJY8qGDRtey8xpA8fHZBB0dXXR3d3d7jYkaUyJiD80GvfWkCQVziCQpMIZBJJUuDG5RiBJQ/Xuu+/S29vLzp07293KiOvo6KCzs5P99ttvUPUGgaQi9Pb2MnHiRLq6uoiIdrczYjKTHTt20Nvby4wZMwZ1jreGJBVh586dTJ06dZ8OAYCIYOrUqUO68jEIJBVjXw+B9wx1ngaBJBXOIJCkUbL//vvvsea2227jmGOO4bOf/Sw/+clP2LRp04j3ZRBI0l7kjjvuYN26dfzgBz8wCCRpX3bzzTdzyimncPzxx3PNNdcAcPnll7Nlyxbmz5/PN7/5TVavXs3XvvY1TjjhBF544YUR68W3j0oqznUPbGTTH/+zpc8582N/yzUXHjuo2rVr19LT08NTTz1FZrJgwQJ+9atfceedd/KLX/yCRx99lAMPPJCenh4+/elPs2jRopb2OpBBIEmjbO3ataxdu5YTTzwRgL6+Pnp6ejjrrLPa0o9BIKk4g/3NfaRkJldeeSVf+MIX2trHe1wjkKRRNnfuXO666y76+voA2LZtG6+++ur/q5s4cSJ/+ctfRrwfg0CSRtmcOXO49NJLOf3005k1axaLFi1q+AN/8eLF3HzzzZx44okjulgcmTliTz5SarVa+odpJA3Fc889xzHHHNPuNkZNo/lGxIbMrA2s9YpAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKQ2ueCCC/jzn//8gTVnn302jd4u/8wzz7BmzZqW9GEQSFIbZCYPPvggkydPHtb5e10QRMS8iHg+IjZHxLIGxydExKrq+JMR0TXg+PSI6IuIr7aiH0naG23dupWjjz6ayy67jOOOO45x48bx2muvAXD99ddz9NFHc+aZZ3LJJZdwyy23/PW8e++9l9mzZ/PJT36Sxx9/nHfeeYerr76aVatWccIJJ7Bq1aqm+mr6Q+ciYhzwHeB8oBdYHxGrM7P+ryl8DngjM4+MiMXAjcA/1h3/d+DnzfYiSYPy82Xwym9a+5yHzIL5N+yxrKenh5UrV3LaaafR1dUFwPr167n//vt59tlneffddznppJM4+eST/3rOrl27eOqpp1izZg3XXXcdDz/8MMuXL6e7u5vbb7+96dZbcUUwG9icmVsy8x3gHmDhgJqFwMpq+z7g3Kj+unJEXAS8CGxsQS+StFc74ogjOO2009439sQTT7Bw4UI6OjqYOHEiF1544fuOX3zxxQCcfPLJbN26teU9teJjqA8DXqrb7wVO3V1NZu6KiDeBqRGxE/g6/VcTH3hbKCKWAksBpk+f3oK2JRVrEL+5j5SPfvSjQz5nwoQJAIwbN45du3a1uqW2LxZfC9yamX17KszMFZlZy8zatGnTRr4zSRolZ5xxBg888AA7d+6kr6+PBx98cI/ntPIjqlsRBNuAw+v2O6uxhjURMR6YBOyg/8rhpojYCnwJ+NeIuKIFPUnSmHHKKaewYMECjj/+eObPn8+sWbOYNGnSB55zzjnnsGnTppYsFjf9MdTVD/bfA+fS/wN/PXBpZm6sq/kiMCszL68Wiy/OzH8Y8DzXAn2ZeQt74MdQSxqqvf1jqPv6+th///156623OOuss1ixYgUnnXTSsJ9vKB9D3fQaQXXP/wrgIWAccFdmboyI5UB3Zq4Gvgd8PyI2A68Di5t9XUnalyxdupRNmzaxc+dOlixZ0lQIDFVL/mZxZq4B1gwYu7pueyfw93t4jmtb0YskjUV3331321673YvFkjRqxuJfZByOoc7TIJBUhI6ODnbs2LHPh0FmsmPHDjo6OgZ9TktuDUnS3q6zs5Pe3l62b9/e7lZGXEdHB52dnYOuNwgkFWG//fZjxowZ7W5jr+StIUkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYVrSRBExLyIeD4iNkfEsgbHJ0TEqur4kxHRVY2fHxEbIuI31ddPtaIfSdLgNR0EETEO+A4wH5gJXBIRMweUfQ54IzOPBG4FbqzGXwMuzMxZwBLg+832I0kamlZcEcwGNmfmlsx8B7gHWDigZiGwstq+Dzg3IiIzf52Zf6zGNwIfjogJLehJkjRIrQiCw4CX6vZ7q7GGNZm5C3gTmDqg5jPA05n5dgt6kiQN0vh2NwAQEcfSf7tozgfULAWWAkyfPn2UOpOkfV8rrgi2AYfX7XdWYw1rImI8MAnYUe13Aj8GLsvMF3b3Ipm5IjNrmVmbNm1aC9qWJEFrgmA9cFREzIiIDwGLgdUDalbTvxgMsAj4ZWZmREwGfgYsy8wnWtCLJGmImg6C6p7/FcBDwHPAjzJzY0Qsj4gFVdn3gKkRsRn4CvDeW0yvAI4Ero6IZ6rHQc32JEkavMjMdvcwZLVaLbu7u9vdhiSNKRGxITNrA8f9n8WSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBWuJUEQEfMi4vmI2BwRyxocnxARq6rjT0ZEV92xK6vx5yNibiv6kSQNXtNBEBHjgO8A84GZwCURMXNA2eeANzLzSOBW4Mbq3JnAYuBYYB5wR/V8kqRR0oorgtnA5szckpnvAPcACwfULARWVtv3AedGRFTj92Tm25n5IrC5ej5J0ihpRRAcBrxUt99bjTWsycxdwJvA1EGeC0BELI2I7ojo3r59ewvaliTBGFoszswVmVnLzNq0adPa3Y4k7TNaEQTbgMPr9jursYY1ETEemATsGOS5kqQR1IogWA8cFREzIuJD9C/+rh5QsxpYUm0vAn6ZmVmNL67eVTQDOAp4qgU9SZIGaXyzT5CZuyLiCuAhYBxwV2ZujIjlQHdmrga+B3w/IjYDr9MfFlR1PwI2AbuAL2bmfzfbkyRp8KL/F/OxpVarZXd3d7vbkKQxJSI2ZGZt4PiYWSyWJI0Mg0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXBNBUFEHBAR6yKip/o6ZTd1S6qanohYUo19JCJ+FhG/i4iNEXFDM71Ikoan2SuCZcAjmXkU8Ei1/z4RcQBwDXAqMBu4pi4wbsnMvwNOBM6IiPlN9iNJGqJmg2AhsLLaXglc1KBmLrAuM1/PzDeAdcC8zHwrMx8FyMx3gKeBzib7kSQNUbNBcHBmvlxtvwIc3KDmMOCluv3eauyvImIycCH9VxWSpFE0fk8FEfEwcEiDQ1fV72RmRkQOtYGIGA/8ELgtM7d8QN1SYCnA9OnTh/oykqTd2GMQZOZ5uzsWEX+KiEMz8+WIOBR4tUHZNuDsuv1O4LG6/RVAT2Z+ew99rKhqqdVqQw4cSVJjzd4aWg0sqbaXAD9tUPMQMCciplSLxHOqMSLiG8Ak4EtN9iFJGqZmg+AG4PyI6AHOq/aJiFpEfBcgM18HrgfWV4/lmfl6RHTSf3tpJvB0RDwTEZ9vsh9J0hBF5ti7y1Kr1bK7u7vdbUjSmBIRGzKzNnDc/1ksSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhmgqCiDggItZFRE/1dcpu6pZUNT0RsaTB8dUR8dtmepEkDU+zVwTLgEcy8yjgkWr/fSLiAOAa4FRgNnBNfWBExMVAX5N9SJKGqdkgWAisrLZXAhc1qJkLrMvM1zPzDWAdMA8gIvYHvgJ8o8k+JEnD1GwQHJyZL1fbrwAHN6g5DHipbr+3GgO4HvgW8NaeXigilkZEd0R0b9++vYmWJUn1xu+pICIeBg5pcOiq+p3MzIjIwb5wRJwAfCIzvxwRXXuqz8wVwAqAWq026NeRJH2wPQZBZp63u2MR8aeIODQzX46IQ4FXG5RtA86u2+8EHgNOB2oRsbXq46CIeCwzz0aSNGqavTW0GnjvXUBLgJ82qHkImBMRU6pF4jnAQ5n5H5n5sczsAs4Efm8ISNLoazYIbgDOj4ge4Lxqn4ioRcR3ATLzdfrXAtZXj+XVmCRpLxCZY+92e61Wy+7u7na3IUljSkRsyMzawHH/Z7EkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwkZnt7mHIImI78Id29zFEBwKvtbuJUeacy+Ccx44jMnPawMExGQRjUUR0Z2at3X2MJudcBuc89nlrSJIKZxBIUuEMgtGzot0NtIFzLoNzHuNcI5CkwnlFIEmFMwgkqXAGQQtFxAERsS4ieqqvU3ZTt6Sq6YmIJQ2Or46I3458x81rZs4R8ZGI+FlE/C4iNkbEDaPb/dBExLyIeD4iNkfEsgbHJ0TEqur4kxHRVXfsymr8+YiYO5p9N2O4c46I8yNiQ0T8pvr6qdHufTia+R5Xx6dHRF9EfHW0em6JzPTRogdwE7Cs2l4G3Nig5gBgS/V1SrU9pe74xcDdwG/bPZ+RnjPwEeCcquZDwOPA/HbPaTfzHAe8AHy86vVZYOaAmn8B7qy2FwOrqu2ZVf0EYEb1POPaPacRnvOJwMeq7eOAbe2ez0jOt+74fcC9wFfbPZ+hPLwiaK2FwMpqeyVwUYOaucC6zHw9M98A1gHzACJif+ArwDdGoddWGfacM/OtzHwUIDPfAZ4GOkeh5+GYDWzOzC1Vr/fQP/d69f8W9wHnRkRU4/dk5tuZ+SKwuXq+vd2w55yZv87MP1bjG4EPR8SEUel6+Jr5HhMRFwEv0j/fMcUgaK2DM/PlavsV4OAGNYcBL9Xt91ZjANcD3wLeGrEOW6/ZOQMQEZOBC4FHRqLJFtjjHOprMnMX8CYwdZDn7o2amXO9zwBPZ+bbI9Rnqwx7vtUvcV8HrhuFPltufLsbGGsi4mHgkAaHrqrfycyMiEG/NzciTgA+kZlfHnjfsd1Gas51zz8e+CFwW2ZuGV6X2htFxLHAjcCcdvcywq4Fbs3MvuoCYUwxCIYoM8/b3bGI+FNEHJqZL0fEocCrDcq2AWfX7XcCjwGnA7WI2Er/9+WgiHgsM8+mzUZwzu9ZAfRk5rdb0O5I2QYcXrffWY01qumtwm0SsGOQ5+6NmpkzEdEJ/Bi4LDNfGPl2m9bMfE8FFkXETcBk4H8iYmdm3j7ybbdAuxcp9qUHcDPvXzi9qUHNAfTfR5xSPV4EDhhQ08XYWSxuas70r4fcD/xNu+eyh3mOp3+Rewb/t5B47ICaL/L+hcQfVdvH8v7F4i2MjcXiZuY8uaq/uN3zGI35Dqi5ljG2WNz2BvalB/33Rh8BeoCH637Y1YDv1tX9M/0LhpuBf2rwPGMpCIY9Z/p/40rgOeCZ6vH5ds/pA+Z6AfB7+t9ZclU1thxYUG130P+Okc3AU8DH6869qjrvefbSd0a1cs7AvwH/Vfd9fQY4qN3zGcnvcd1zjLkg8CMmJKlwvmtIkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTC/S9JTVfWjwybKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arKFuiiZvfq7"
      },
      "source": [
        "# 予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw8_eIrPzOwf"
      },
      "source": [
        "def translate_sentence(encoder, decoder_left, decoder_right, sentence, title, device, max_length=50):\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token for token in tokenizer(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, title.init_token)\n",
        "    tokens.append(title.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [title.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs_left = [title.vocab.stoi[\"<sos>\"]]\n",
        "    outputs_right = [title.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for i in range(max_length):\n",
        "        trg_tensor_left = torch.LongTensor(outputs_left).unsqueeze(1).to(device)\n",
        "        trg_tensor_right = torch.LongTensor(outputs_right).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            memory = encoder(sentence_tensor) # これfor文の外でもいい気がする\n",
        "            output_left = decoder_left(trg_tensor_left, memory)\n",
        "            output_right = decoder_right(trg_tensor_right, memory)\n",
        "\n",
        "        best_guess_left = output_left.argmax(2)[-1, :].item()\n",
        "        best_guess_right = output_right.argmax(2)[-1, :].item()\n",
        "        outputs_left.append(best_guess_left)\n",
        "        outputs_right.append(best_guess_right)\n",
        "\n",
        "        if best_guess_right == title.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence_right = [title.vocab.itos[idx] for idx in outputs_right]\n",
        "    translated_sentence_left = [title.vocab.itos[idx] for idx in outputs_left]\n",
        "    # remove start token\n",
        "    return translated_sentence_left[1:], translated_sentence_right[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuu7fwi-0CNh"
      },
      "source": [
        "sentence = \"▶︎質疑応答◀︎ヒトは神を創った、自分の愚かさを正当化するために\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lfd6qrfvhVq"
      },
      "source": [
        "translated_sentence = translate_sentence(\n",
        "        encoder, decoder_left, decoder_right, sentence, title, device, max_length=50\n",
        "    )\n",
        "print(f\"Translated example sentence: \\n {translated_sentence}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8qRFfL-kvk1"
      },
      "source": [
        "# Decoderだけの場合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ViPgwohDvUR"
      },
      "source": [
        "データ定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-uUBhV_DvF_",
        "outputId": "c9036485-2b75-49ec-a202-244acf31e74f"
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "        (train_data, test_data),\n",
        "        batch_size=batch_size,\n",
        "        sort_within_batch=True,\n",
        "        sort_key=lambda x: len(x.title),\n",
        "        device=device,\n",
        "        )"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT2hpVJjCgb6"
      },
      "source": [
        "モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKJhtQcvCi_G"
      },
      "source": [
        "encoder = Encoder(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "decoder = Decoder(\n",
        "    embedding_size,\n",
        "    trg_vocab_size,\n",
        "    num_heads,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device\n",
        ").to(device)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THbw_gnQCjmE"
      },
      "source": [
        "optim定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xg1RCTCmJ3"
      },
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "encoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    encoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "decoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    decoder_optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "pad_idx = 0\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOd9iCKnCmnu"
      },
      "source": [
        "学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0m8HMr-Cdgl",
        "outputId": "326ede2c-1f84-485b-824e-17f7e7fdfba0"
      },
      "source": [
        "mean_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    losses = []\n",
        "    output2bests = []\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        '''\n",
        "        入力データ\n",
        "        '''\n",
        "        inp_data = batch.title.to(device)\n",
        "        target = batch.title.to(device)\n",
        "\n",
        "        '''\n",
        "        encoderとdecoderに渡す\n",
        "        '''\n",
        "        memory = encoder(inp_data)\n",
        "        output = decoder(target[:-1, :], memory)\n",
        "\n",
        "        '''\n",
        "        勾配の初期化\n",
        "        '''\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        '''\n",
        "        loss計算\n",
        "        '''\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        '''\n",
        "        誤差逆伝搬\n",
        "        '''\n",
        "        loss.backward(retain_graph=True)\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "\n",
        "        '''\n",
        "        重みの更新\n",
        "        '''\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        '''\n",
        "        予測\n",
        "        '''\n",
        "        if batch_idx != 0: continue\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        sentence_list_str, sentence_list_int = batch2title(batch, title, batch_size)\n",
        "        batch_score = 0\n",
        "        for sentence_str, sentence_int in zip(sentence_list_str, sentence_list_int):\n",
        "            pred_num, pred_str = title2title(encoder, decoder, sentence_str, title, device, max_len)\n",
        "            score = cal_accuracy(sentence_str, pred_str)\n",
        "            batch_score += score\n",
        "        print(sentence_str)\n",
        "        print(pred_str)\n",
        "        print(\"正解率： \", batch_score / batch_size)\n",
        "\n",
        "    '''\n",
        "    バッチの平均ロスを計算\n",
        "    '''\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "\n",
        "    '''\n",
        "    スケジューラー（学習率の調整）\n",
        "    '''\n",
        "    decoder_scheduler.step(mean_loss)\n",
        "    '''\n",
        "    loss append\n",
        "    '''\n",
        "    mean_losses.append(mean_loss)\n",
        "    print(\"loss: \", mean_loss)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['【', 'GACKT×', '中田', '敦彦', '】', '海外', '移住', '・', '生き方', '・', 'ビジネス', '・', 'ボランティア', 'を', '語る']\n",
            "['【', 'GACKT×', '敦彦', '敦彦', '海外', '海外', '海外', '・', '生き方', '・', 'ビジネス', '・', 'ボランティア', 'を', 'を', '語る']\n",
            "正解率：  0.6473788017037222\n",
            "loss:  1.139825604737751\n",
            "[Epoch 1 / 50]\n",
            "['Vlog', '【', 'フィルム', 'カメラ', 'で', 'あそぼ', 'う', '！', '！】～', 'ニコン', 'FE', '～']\n",
            "['【', 'フィルム', 'フィルム', 'カメラ', 'で', 'あそぼ', 'う', '！', '！】～', 'ニコン', '～', '～']\n",
            "正解率：  0.7166896768115434\n",
            "loss:  1.3592447146536812\n",
            "[Epoch 2 / 50]\n",
            "['1', '億', '円', '寄付', 'し', 'て', 'コロナ', '医療', '支援', '募金', 'を', '立ち', '上げ', 'まし', 'た', '。', '僕', 'と', '一緒', 'に', '募金', 'し', 'て', '命', 'を', '守る', '人', 'を', '支え', 'ませ', 'ん', 'か', '？']\n",
            "['1', '億', '円', '寄付', 'し', 'て', 'コロナ', 'コロナ', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '支援', '募金', 'と', '募金', '募金', 'と', '一緒', 'と', 'ませ', 'と', 'ませ', 'ん', 'ん', 'ん', 'ん', 'ませ', 'ん', 'ん']\n",
            "正解率：  0.19185659814143927\n",
            "loss:  4.450397090306358\n",
            "[Epoch 3 / 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['【', 'ボタン', '式', '/', 'Bluetooth', '搭載', 'の', 'MP', '3', 'プレーヤー', '】', '音質', '良し', '、', '画面', '良し', '、', '使い', 'やす', 'さ', '良し', '、', '機能', '良し', '！', '！']\n",
            "['良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し', '良し']\n",
            "正解率：  0.19671135341159457\n",
            "loss:  3.84639545092507\n",
            "[Epoch 4 / 50]\n",
            "['【', 'コンビニ', '新', '商品', '】', 'JUICY', 'DROP', 'GUMMIES', '！', 'レビュー', '！', 'ジューシードロップグミ', 'Japanese', 'Sweets', 'Review', '【', 'セブン', '】', '【#', '49', '】']\n",
            "['！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！', '！']\n",
            "正解率：  0.13478710382277284\n",
            "loss:  3.6983810757833813\n",
            "[Epoch 5 / 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['【', '万', '乳', '引力', '】', '男', 'は', 'なぜ', '【', '巨乳', 'に', '惹か', 'れる', 'の', 'か', '】']\n",
            "['【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【', '【']\n",
            "正解率：  0.11877659468292077\n",
            "loss:  3.598333169543554\n",
            "[Epoch 6 / 50]\n",
            "['幸せ', 'な', '結婚', 'の', '【', '絶対', '条件', '】', 'が', '判明', '【', 'カリフォルニア', '大学', '最新', '研究', '】']\n",
            "['判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明', '判明']\n",
            "正解率：  0.1083322774196349\n",
            "loss:  3.2168736552435253\n",
            "[Epoch 7 / 50]\n",
            "['何', 'を', 'やっ', 'て', 'も', '【', '続か', 'ない', '人', '】', 'の', '問題', '点', 'TOP', '5']\n",
            "['も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も', 'も']\n",
            "正解率：  0.3699145920495941\n",
            "loss:  2.696746580184452\n",
            "[Epoch 8 / 50]\n",
            "['【', '兄弟', '対決', '】', 'ヒカキン', 'vs', 'セイ', 'キン', '声優', 'バトル', '！', '【', 'アプモン', '】']\n",
            "['【', '兄弟', '兄弟', '】', 'ヒカキン', 'vs', 'vs', '！', 'アプモン', 'バトル', 'アプモン', 'アプモン', 'アプモン', 'アプモン']\n",
            "正解率：  0.2779280964650152\n",
            "loss:  1.9423562080141097\n",
            "[Epoch 9 / 50]\n",
            "['【', 'ランキング', '】', 'ヒカキン', 'か', '゙', 'ハマっ', 'てる', 'コンヒ', '゙', 'ニ', 'お', 'やつ', 'トップ', '３', '【', '2020', '年', '5', '月', '編', '】']\n",
            "['【', 'ランキング', '】', 'ヒカキン', 'か', '゙', '゙', 'てる', 'てる', '゙', 'ニ', 'トップ', 'トップ', 'やつ', '5', 'トップ', 'トップ', '5', '【', '】', '【', '【', '】', '【', '】', '【', '】']\n",
            "正解率：  0.18436056509092486\n",
            "Epoch    60: reducing learning rate of group 0 to 3.0000e-05.\n",
            "loss:  1.8645827476940458\n",
            "[Epoch 10 / 50]\n",
            "['【', '448', '台', '】', '宇宙', '一', 'クレーン', 'ゲーム', 'か', '゙', '多い', '超', '巨大', 'ケ', '゙', 'ーセン', 'て', '゙', '景品', '取り', 'まくる', 'w', '【', 'UFO', 'キャッチャー', '】']\n",
            "['【', '448', '台', '】', '一', '一', 'ゲーム', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', '゙', 'w']\n",
            "正解率：  0.27156697628217846\n",
            "loss:  1.8972516476161896\n",
            "[Epoch 11 / 50]\n",
            "['【', 'ロス', 'チャイルド', '家', '②】', 'ユダヤ', '人', '大', '富豪', 'にまつわる', '陰謀', '論', 'の', '真実']\n",
            "['【', 'ロス', 'チャイルド', '家', '②】', 'ユダヤ', '人', '大', '陰謀', '陰謀', '陰謀', '陰謀', '陰謀', '陰謀']\n",
            "正解率：  0.5447980182116169\n",
            "loss:  1.283098947907251\n",
            "[Epoch 12 / 50]\n",
            "['【', 'ネットワーク', 'ビジネス', '】', 'について', '話し', 'ます']\n",
            "['【', 'ネットワーク', 'ビジネス', '】', 'について', '話し', 'ます']\n",
            "正解率：  0.862852168247238\n",
            "loss:  1.1439066902985648\n",
            "[Epoch 13 / 50]\n",
            "['好か', 'れる', 'お', '世辞', '、', '嫌わ', 'れる', 'お', '世辞']\n",
            "['好か', 'れる', 'お', '世辞', '、', '嫌わ', 'れる', 'お', '世辞']\n",
            "正解率：  0.854033503313369\n",
            "loss:  1.0522790248431857\n",
            "[Epoch 14 / 50]\n",
            "['【', '最高', 'の', '睡眠', '②】', '新型', 'コロナ', 'ウイルス', 'から', '身', 'を', '守る', '安眠', '法']\n",
            "['【', '最高', 'の', '睡眠', '②】', '新型', 'コロナ', 'ウイルス', 'から', '守る', '守る', '守る', '安眠', '安眠']\n",
            "正解率：  0.5291990132161716\n",
            "loss:  0.965026266281567\n",
            "[Epoch 15 / 50]\n",
            "['【', 'USB', 'マイク', 'の', '完成', '形', '】', 'HyperX', 'の', 'QuadCast', 'を', '開封', 'レビュー', '！']\n",
            "['【', 'USB', 'マイク', 'の', '完成', '形', '】', 'の', 'の', '開封', '開封', '開封', '開封', '開封']\n",
            "正解率：  0.5762667054602376\n",
            "loss:  0.8879166796566949\n",
            "[Epoch 16 / 50]\n",
            "['即', '完売', 'の', 'スプラトゥーン', '2', 'nanaco', 'フィギュア', 'が', 'ｷﾀ', '━(', 'ﾟ', '∀', 'ﾟ', ')━！', 'ヒカキン', 'nanaco', 'デビュー', '!']\n",
            "['即', '完売', 'の', 'スプラトゥーン', '2', 'nanaco', 'フィギュア', 'が', 'ｷﾀ', 'ｷﾀ', 'ﾟ', 'ﾟ', 'ﾟ', 'ﾟ', 'ヒカキン', 'nanaco', '!', '!']\n",
            "正解率：  0.5275229197047003\n",
            "loss:  0.8417252233577153\n",
            "[Epoch 17 / 50]\n",
            "['【', '感動', 'の', '涙', '】', '39', '℃', 'の', '熱', 'で', 'ダウン', 'し', 'た', 'カメラマン', 'の', '兄', 'に', 'お', '粥', '作っ', 'て', '家', 'まで', '持っ', 'て', 'いっ', 'たら', '…']\n",
            "['【', '感動', 'の', '涙', '】', '39', '℃', 'の', 'の', 'で', 'し', 'し', 'た', 'た', 'の', 'お', 'お', 'お', 'お', 'お', 'て']\n",
            "正解率：  0.33701620038097096\n",
            "loss:  0.8325313355714555\n",
            "[Epoch 18 / 50]\n",
            "['【', '繊細', 'さん', 'の', '幸せ', 'リスト', '①】', '繊細', 'さ', 'は', '「', '幸せ', 'を', '感じる', 'ため', '」', 'の', '才能']\n",
            "['【', '繊細', 'さん', 'の', '幸せ', 'リスト', '①】', '繊細', 'さ', 'は', 'は', '幸せ', '幸せ', '感じる', '」', 'を', 'を', 'を', 'の', 'の', 'の', 'の', 'の', 'の', 'の', 'の', 'の']\n",
            "正解率：  0.5036868585736632\n",
            "loss:  0.7768785667324823\n",
            "[Epoch 19 / 50]\n",
            "['いい', '仕事', 'トップ', 'ランキング', '&', 'amp', ';', 'ヤバイ', '仕事', 'ワースト', 'ランキング']\n",
            "['いい', '仕事', 'トップ', 'ランキング', '&', 'amp', ';', '仕事', '仕事', 'ワースト']\n",
            "正解率：  0.7532346210339878\n",
            "loss:  0.8187822761043669\n",
            "[Epoch 20 / 50]\n",
            "['ヒカキン', 'から', '重大', '発表', 'が', 'あり', 'ます']\n",
            "['ヒカキン', 'から', '重大', '発表', 'が', 'あり', 'ます']\n",
            "正解率：  0.8550412659423021\n",
            "loss:  0.7216687417692609\n",
            "[Epoch 21 / 50]\n",
            "['【', 'ドッキリ', '】', '超', 'ヒカキン', '好き', 'な', '女の子', 'の', '家', 'に', 'いる', 'ト', '゙', 'ッキリ', 'し', 'たら', '大変', 'な', 'こと', 'に', 'w', '【', '感動', '】']\n",
            "['【', 'ドッキリ', '】', '超', 'ヒカキン', '好き', 'な', '女の子', 'の', '家', 'に', 'いる', 'ト', 'ト', 'ッキリ', 'し', 'し', 'な', '感動', 'こと', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に', 'に']\n",
            "正解率：  0.39466142751882766\n",
            "loss:  0.687292718698108\n",
            "[Epoch 22 / 50]\n",
            "['【', '大麻', '②】〜', '麻薬', 'から', '自分', 'の', '身', 'を', '守る', 'ため', 'の', '授業', '、', '日本', 'の', '大麻', '合法', '化', 'は', 'どう', 'なる', '？', '〜']\n",
            "['【', '大麻', '②】〜', '麻薬', 'から', '自分', 'の', 'の', 'を', '守る', 'ため', 'の', 'の', '、', '日本', 'の', '合法', 'は', 'は', 'は', '？', 'なる']\n",
            "正解率：  0.4514833678634449\n",
            "loss:  0.6936544657699646\n",
            "[Epoch 23 / 50]\n",
            "['【', '初めて', '営業', 'する', '人', '】', '【', '営業', 'が', '苦手', 'な', '人', '】', 'の', 'ため', 'の', '動画', 'です', '^^♪']\n",
            "['【', '初めて', '営業', 'する', '人', '】', '【', '営業', '苦手', '苦手', 'な', '人', 'の', 'の', '動画', '動画', '動画', '^^♪', '^^♪']\n",
            "正解率：  0.6312139446116573\n",
            "loss:  0.6512865813242065\n",
            "[Epoch 24 / 50]\n",
            "['【', 'FIRE', '①】', '最速', 'で', '経済', '的', '自立', 'を', '実現', 'する', '方法', '（', 'Financial', 'Freedom', '）']\n",
            "['【', 'FIRE', '①】', '最速', 'で', '経済', '的', '自立', 'を', '実現', 'する', '方法', '（', '（', '）', '）']\n",
            "正解率：  0.6616129364850433\n",
            "loss:  0.6820392561337304\n",
            "[Epoch 25 / 50]\n",
            "['会計', '払え', 'ず', 'ATM', 'に', '…', '1', '皿', '2500', '円', 'の', 'うに', '牛', 'を', '限界', 'まで', '食べ', '続け', 'たら', '支払い', 'いくら', 'に', 'なる', '？']\n",
            "['会計', '払え', 'ず', 'に', 'に', '…', '1', '皿', '2500', '円', 'の', 'うに', 'うに', 'を', '限界', 'まで', '食べ', '続け', 'たら', 'に', 'なる', 'に', 'なる', 'なる', 'なる', 'なる']\n",
            "正解率：  0.4788387461436041\n",
            "loss:  0.6401862155586954\n",
            "[Epoch 26 / 50]\n",
            "['【', 'USB', 'マイク', 'の', '完成', '形', '】', 'HyperX', 'の', 'QuadCast', 'を', '開封', 'レビュー', '！']\n",
            "['【', 'USB', 'マイク', 'マイク', '完成', '形', '】', 'の', 'の', 'を', 'を', '開封', 'レビュー', '！']\n",
            "正解率：  0.5974731337636443\n",
            "loss:  0.5932616880015721\n",
            "[Epoch 27 / 50]\n",
            "['【', 'いざ', '出陣', '】', '2500', '万', '円', 'で', '購入', 'し', 'た', 'マセラティ', '納車', 'し', 'まし', 'た']\n",
            "['【', 'いざ', '出陣', '】', '2500', '万', '円', 'で', '購入', 'し', 'た', 'マセラティ', '納車', 'し', 'まし', 'た']\n",
            "正解率：  0.7543966879124915\n",
            "loss:  0.5886924154465161\n",
            "[Epoch 28 / 50]\n",
            "['【', '未来', '予測', '①】', '2030', '年', 'の', '世界']\n",
            "['【', '未来', '予測', '①】', '2030', '年', 'の', '世界']\n",
            "正解率：  0.899971865355232\n",
            "loss:  0.5486015718844202\n",
            "[Epoch 29 / 50]\n",
            "['【', '緊急', '事態', '】', 'ヒカル', 'が', '酒', 'で', '完全', 'に', 'ダウン', 'し', 'まし', 'た', '…']\n",
            "['【', '緊急', '事態', '】', 'ヒカル', 'が', '酒', 'で', '完全', 'に', 'ダウン', 'し', 'し', 'た', '…']\n",
            "正解率：  0.8246756285987902\n",
            "loss:  0.5590817273136169\n",
            "[Epoch 30 / 50]\n",
            "['自分', 'を', '疑える', 'の', 'は', '成長', 'できる', '証拠', 'だ', '。', '自分', 'を', '疑わ', 'ない', '人', 'に', '成長', 'は', 'ない', '【', '質疑', '応答', '#', '15', '】']\n",
            "['自分', 'を', '疑える', 'の', 'は', '成長', 'できる', 'だ', 'だ', '。', '自分', 'を', 'ない', 'ない', '人', 'に', '成長', 'は', 'ない', '【', '質疑', '応答', '質疑', '質疑', '質疑', '質疑', '質疑', '#', '#']\n",
            "正解率：  0.522040417321855\n",
            "loss:  0.5422259760754449\n",
            "[Epoch 31 / 50]\n",
            "['【', '食', 'レポ', '】', 'ついに', '辿り', '着', 'い', 'た', '「', '極', 'じゃ', 'が', '」', 'こだわり', 'の', '厳選', 'し', 'お', '味', '食べ', 'て', 'み', 'た', '！', 'カルビー', '！【#', '140', '】']\n",
            "['【', '食', 'レポ', '】', 'ついに', '辿り', '着', 'い', 'た', '「', 'じゃ', 'じゃ', '」', '」', '」', '」', 'し', 'お', 'し', 'て', 'の', 'み', 'み', 'み']\n",
            "正解率：  0.3995960936351299\n",
            "loss:  0.49695848224181977\n",
            "[Epoch 32 / 50]\n",
            "['なぜ', 'YouTube', '初心者', 'は', '【', '100', '本', 'の', '動画', '】', 'が', '作れ', 'ない', 'の', 'か', '？']\n",
            "['なぜ', 'なぜ', 'なぜ', 'なぜ', '100', '100', '本', 'の', '動画', '】', 'が', '作れ', 'ない', 'の', 'か', '？']\n",
            "正解率：  0.8013566710706681\n",
            "loss:  0.511031644507533\n",
            "[Epoch 33 / 50]\n",
            "['【', '東京', '五輪', '延期', '①】', 'オリンピック', 'の', '光', 'と', '影']\n",
            "['【', '東京', '五輪', '延期', '①】', 'オリンピック', 'オリンピック', '光', 'と', '影']\n",
            "正解率：  0.8837506688281637\n",
            "loss:  0.5153299007150862\n",
            "[Epoch 34 / 50]\n",
            "['わが子', 'の', '【', '進路', '選択', '】', 'を', '考え', 'て', 'ます', '..', 'f', '^^;']\n",
            "['わが子', 'の', '【', '進路', '選択', '】', 'を', '考え', 'て', 'ます', '..', '^^;', '^^;']\n",
            "正解率：  0.8684095373797284\n",
            "loss:  0.49406500728357405\n",
            "[Epoch 35 / 50]\n",
            "['【', '毎日', '投稿', '225', '日', '目', '】', '脱サラ', '底辺', '素人', 'YouTuber', 'の', 'チャンネル', '登録', '者', 'は', '増え', 'た', 'の', 'か', '？', '【', '第', '31', '回', '振り返り', '】【#', '225', '】']\n",
            "['【', '毎日', '投稿', '225', '日', '目', '】', '脱サラ', '底辺', '素人', 'YouTuber', 'の', 'チャンネル', '登録', '者', 'は', 'た', 'の', 'か', '【', '【']\n",
            "正解率：  0.49323102036547956\n",
            "loss:  0.5025594556142413\n",
            "[Epoch 36 / 50]\n",
            "['【', '神', 'お', 'やつ', '】', 'DNA', 'を', '修復', 'する', '最強', 'お', 'やつ', 'が', 'こちら']\n",
            "['【', '神', 'お', 'やつ', '】', 'DNA', 'を', '修復', 'する', 'お', 'お', 'やつ', 'が', 'こちら']\n",
            "正解率：  0.7047038059568517\n",
            "loss:  0.4980384053455459\n",
            "[Epoch 37 / 50]\n",
            "['【', 'バビロン', '大', '富豪', 'の', '教え', '②】']\n",
            "['【', 'バビロン', '大', '富豪', 'の', '教え', '②】']\n",
            "正解率：  0.8885551429744107\n",
            "loss:  0.45765529986884856\n",
            "[Epoch 38 / 50]\n",
            "['【', '250', 'ヤード', '越え', '連発', '】', 'プロ', 'の', 'コーチ', 'に', 'ゴルフ', '教わっ', 'たら', '10', '分', 'で', 'ど', '素人', 'ヒカル', 'が', '覚醒', 'し', 'た', 'ww']\n",
            "['【', '250', 'ヤード', '越え', '連発', '】', 'プロ', 'の', 'コーチ', 'に', 'ゴルフ', '教わっ', 'たら', '10', '分', 'で', 'ど', '素人', 'ヒカル', 'ヒカル', '覚醒', 'し', '覚醒', 'し', 'た', 'し', 'た', 'し', 'た', 'ww', 'ww']\n",
            "正解率：  0.633075985031262\n",
            "loss:  0.4581635197594998\n",
            "[Epoch 39 / 50]\n",
            "['【', 'フィルム', 'カメラ', '】', 'で', 'あそぼ', 'う', '！', '！', '【', 'Nikon', 'FG', '】']\n",
            "['【', 'フィルム', 'カメラ', '】', 'で', 'あそぼ', 'う', '！', '！', '【', '【', '】', '】']\n",
            "正解率：  0.9279349980125507\n",
            "loss:  0.4707392334701523\n",
            "[Epoch 40 / 50]\n",
            "['相手', 'の', '考え', 'を', 'ひっくり返す', '絶大', 'な', '効果', 'の', 'ある', 'テクニック', '【', 'Yes', 'and', 'But', '手法', '】']\n",
            "['相手', 'の', '考え', 'を', 'ひっくり返す', '絶大', 'な', '効果', 'の', 'ある', 'テクニック', '【', '【', 'and', '】', '】', '】', '】']\n",
            "正解率：  0.7452953531418408\n",
            "loss:  0.43527336838463\n",
            "[Epoch 41 / 50]\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', '】', 'DELL', 'の', '「', 'AE', '215', '」', 'を', '開封', 'レビュー', '！']\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', '】', 'DELL', 'の', '「', 'AE', '215', '」', '開封', '開封', 'レビュー', '！', '！']\n",
            "正解率：  0.7589736248650787\n",
            "loss:  0.43629666618884555\n",
            "[Epoch 42 / 50]\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', '】', 'DELL', 'の', '「', 'AE', '215', '」', 'を', '開封', 'レビュー', '！']\n",
            "['【', '高', '音質', 'な', '丸', '型', 'スピーカー', 'スピーカー', '】', '「', 'の', '「', '215', '215', '「', '215', '！']\n",
            "正解率：  0.7495826670206635\n",
            "loss:  0.425080795728025\n",
            "[Epoch 43 / 50]\n",
            "['クレーマー', 'を', '華麗', 'に', '受け流す', '話術', 'TOP', '3']\n",
            "['クレーマー', 'を', '華麗', 'に', '受け流す', '話術', '3', '3']\n",
            "正解率：  0.8831037925726523\n",
            "loss:  0.4208172568016582\n",
            "[Epoch 44 / 50]\n",
            "['ヒカキン', '×', 'マホト', '×', 'PDS', 'で', 'やっ', 'て', '欲しい', 'こと', 'ある', '？', 'リクエスト', '募集', '！']\n",
            "['ヒカキン', '×', 'マホト', '×', 'マホト', 'で', 'やっ', 'て', '欲しい', 'こと', 'ある', '？', 'リクエスト', '募集', '！']\n",
            "正解率：  0.9428338536836932\n",
            "loss:  0.4293424844860084\n",
            "[Epoch 45 / 50]\n",
            "['オジサン', '、', '、', '2', '年', '前', 'から', '【', '白斑', '】', 'です']\n",
            "['オジサン', '、', '、', '2', '年', '前', 'から', '【', '白斑', '】', 'です']\n",
            "正解率：  0.8681381922047234\n",
            "loss:  0.3991850562807586\n",
            "[Epoch 46 / 50]\n",
            "['【', 'ミャンマー', '・', 'クーデター', '①】', 'アウンサンスーチー', 'vs', '国軍', 'の', '権力', '闘争', '（', 'Myanmar', '&#', '39', ';', 's', 'power', 'struggle', '）']\n",
            "['【', 'ミャンマー', '・', 'クーデター', '①】', 'アウンサンスーチー', 'vs', '国軍', 'の', '権力', '闘争', '（', '（', '&#', '39', ';', 's', 'power', '）', '）']\n",
            "正解率：  0.7490428679492412\n",
            "loss:  0.4598053712693472\n",
            "[Epoch 47 / 50]\n",
            "['皮', 'こ', '゙と', 'ハ', '゙', 'ナナ', '食', 'へ', '゙てみた', 'w']\n",
            "['皮', 'こ', '゙と', 'ハ', '゙', 'ナナ', '食', 'へ', '゙てみた', 'w', 'w']\n",
            "正解率：  0.8818093064156703\n",
            "loss:  0.41522617502108455\n",
            "[Epoch 48 / 50]\n",
            "['【', 'コス', 'パ', 'の', '高い', '最新', 'ワイヤレスイヤホン', '】', '1', ',', '999', '円', 'で', 'この', '機能', '、', 'コス', 'パ', '良', 'すぎ', 'です', '!!']\n",
            "['【', 'コス', 'パ', 'の', '高い', '最新', 'ワイヤレスイヤホン', '】', '1', '999', '999', '円', 'で', 'この', '機能', 'コス', 'コス', 'コス', 'すぎ', '!!']\n",
            "正解率：  0.6908198251367937\n",
            "loss:  0.4315577650531417\n",
            "[Epoch 49 / 50]\n",
            "['あなた', 'は', '何', 'タイプ', '？', 'ポケモン', '自己', '分析', 'やっ', 'て', 'み', 'た', '！【#', '7', '】']\n",
            "['あなた', 'は', '何', 'タイプ', '？', 'ポケモン', '自己', '分析', 'やっ', 'て', 'み', 'た', '！【#', '7', '】']\n",
            "正解率：  0.9150435829990526\n",
            "loss:  0.3830832086266979\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}